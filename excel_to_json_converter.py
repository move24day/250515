# text_excel_to_json_gdrive.py (UI ì„¤ëª… ìµœì†Œí™”, ì²˜ë¦¬ ê²°ê³¼ ê°„ì†Œí™”)
import streamlit as st
import json
import re
from datetime import datetime, date
import pytz
import pandas as pd

# í•„ìˆ˜ ëª¨ë“ˆ ë¡œë”© (google_drive_helper.py, data.py, state_manager.pyëŠ” ë™ì¼ ê²½ë¡œì— ìˆì–´ì•¼ í•¨)
try:
    import google_drive_helper as gdrive
    import data
    from state_manager import STATE_KEYS_TO_SAVE, MOVE_TYPE_OPTIONS
except ImportError as e:
    st.error(f"í•„ìˆ˜ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}. (google_drive_helper.py, data.py, state_manager.pyë¥¼ í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìœ„ì¹˜ì‹œì¼œì£¼ì„¸ìš”)")
    st.stop()

# ì‹œê°„ëŒ€ ì„¤ì •
try:
    KST = pytz.timezone("Asia/Seoul")
except pytz.UnknownTimeZoneError:
    st.warning("Asia/Seoul ì‹œê°„ëŒ€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ UTCë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‚ ì§œ ì²˜ë¦¬ì— ì˜í–¥ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    KST = pytz.utc

# ê¸°ë³¸ê°’ ì„¤ì •
DEFAULT_CUSTOMER_NAME = "ë¬´ëª…"
DEFAULT_MOVE_TYPE = MOVE_TYPE_OPTIONS[0] if MOVE_TYPE_OPTIONS else "ê°€ì • ì´ì‚¬ ğŸ "
DEFAULT_FROM_METHOD = data.METHOD_OPTIONS[0] if hasattr(data, 'METHOD_OPTIONS') and data.METHOD_OPTIONS else "ì‚¬ë‹¤ë¦¬ì°¨ ğŸªœ"
DEFAULT_TO_METHOD = data.METHOD_OPTIONS[0] if hasattr(data, 'METHOD_OPTIONS') and data.METHOD_OPTIONS else "ì‚¬ë‹¤ë¦¬ì°¨ ğŸªœ"
TODAY_ISO_DATE = datetime.now(KST).date().isoformat()

# --- ê³µí†µ í—¬í¼ í•¨ìˆ˜ ---
def parse_date_flexible(date_str_input, current_year):
    if isinstance(date_str_input, (datetime, date)):
        return date_str_input.date().isoformat()
    if not date_str_input or str(date_str_input).strip().lower() == "ë¯¸ì •":
        return TODAY_ISO_DATE
    date_str = str(date_str_input).strip()
    patterns = [
        (r'(\d{4})\s*[-/ë…„\.]?\s*(\d{1,2})\s*[-/ì›”\.]?\s*(\d{1,2})\s*ì¼?', lambda m: (int(m.group(1)), int(m.group(2)), int(m.group(3)))),
        (r'(\d{1,2})\s*[-/ì›”\.]\s*(\d{1,2})\s*(ì¼?)', lambda m: (current_year, int(m.group(1)), int(m.group(2)))),
        (r'(\d{2})\s*[-/ë…„\.]?\s*(\d{1,2})\s*[-/ì›”\.]?\s*(\d{1,2})\s*ì¼?', lambda m: (2000 + int(m.group(1)), int(m.group(2)), int(m.group(3))))
    ]
    for pattern, extractor in patterns:
        match = re.match(pattern, date_str)
        if match:
            try:
                matched_date_str = match.group(0)
                if len(matched_date_str) != len(date_str) and not date_str[len(matched_date_str):].strip().isspace() and date_str[len(matched_date_str):].strip() != "":
                    continue
                year, month, day = extractor(match)
                return datetime(year, month, day).date().isoformat()
            except ValueError:
                continue
    return None

def normalize_phone_number_for_filename(phone_str):
    if not phone_str or not isinstance(phone_str, str): return None
    return "".join(filter(str.isdigit, phone_str))

def get_default_state():
    return {
        "moving_date": TODAY_ISO_DATE, "customer_name": DEFAULT_CUSTOMER_NAME, "customer_phone": "",
        "base_move_type": DEFAULT_MOVE_TYPE, "from_location": "", "to_location": "", "special_notes": "",
        "from_floor": "", "to_floor": "", "from_method": DEFAULT_FROM_METHOD, "to_method": DEFAULT_TO_METHOD,
        "is_storage_move": False, "apply_long_distance": False, "has_via_point": False,
        "deposit_amount": 0, "adjustment_amount": 0, "issue_tax_invoice": False, "card_payment": False,
        "remove_base_housewife": False, "dispatched_1t":0, "dispatched_2_5t":0, "dispatched_3_5t":0, "dispatched_5t":0,
        "uploaded_image_paths": []
    }

# --- í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ ---
PHONE_REGEX = re.compile(r'(01[016789]-?\d{3,4}-?\d{4}|0\d{1,2}-?\d{3,4}-?\d{4})')
MOVE_TYPE_KEYWORDS_TEXT = {"ê°€ì •": ["ê°€ì •", "ê°€"], "ì‚¬ë¬´ì‹¤": ["ì‚¬ë¬´ì‹¤", "ì‚¬"]}

def extract_floor_from_address(address_str):
    if not address_str: return "", ""
    floor_match = re.search(r'^(.*?)(\s*(\d+)\s*(ì¸µ|F|f))$', address_str.strip(), re.IGNORECASE)
    if floor_match: return floor_match.group(1).strip(), floor_match.group(3)
    return address_str.strip(), ""

def parse_line_to_json_flexible(line_text, current_year, line_number_display=""):
    state = get_default_state()
    original_line = line_text.strip()
    if not original_line: return None, None, f"{line_number_display}ë¹ˆ ì¤„"

    phone_match = PHONE_REGEX.search(original_line)
    if not phone_match: return None, None, f"{line_number_display}ì „í™”ë²ˆí˜¸ ì—†ìŒ (í•„ìˆ˜)"
    state["customer_phone"] = phone_match.group(0)
    filename_phone_part = normalize_phone_number_for_filename(state["customer_phone"])
    if not filename_phone_part: return None, None, f"{line_number_display}ìœ íš¨í•˜ì§€ ì•Šì€ ì „í™”ë²ˆí˜¸"

    before_phone = original_line[:phone_match.start()].strip()
    after_phone = original_line[phone_match.end():].strip()

    if '\t' in before_phone: parts_before_phone = [p.strip() for p in before_phone.split('\t') if p.strip()]
    else: parts_before_phone = [p.strip() for p in re.split(r'\s{2,}', before_phone) if p.strip()] or ([before_phone] if before_phone else [])

    potential_name_parts = []; date_found = False
    for part in parts_before_phone:
        parsed_date = parse_date_flexible(part, current_year)
        if parsed_date:
            if not date_found: state["moving_date"] = parsed_date; date_found = True
        else: potential_name_parts.append(part)
    if potential_name_parts: state["customer_name"] = " ".join(potential_name_parts)
    if not date_found: state["moving_date"] = TODAY_ISO_DATE # ëª…ì‹œì  ë‚ ì§œ ì—†ìœ¼ë©´ ì˜¤ëŠ˜

    if '\t' in after_phone: parts_after_phone = [p.strip() for p in after_phone.split('\t') if p.strip()]
    else: parts_after_phone = [p.strip() for p in re.split(r'\s{2,}', after_phone) if p.strip()] or ([after_phone] if after_phone else [])
    
    part_index = 0
    if part_index < len(parts_after_phone):
        current_part = parts_after_phone[part_index]
        for type_name, keywords in MOVE_TYPE_KEYWORDS_TEXT.items():
            if any(keyword == current_part.lower() for keyword in keywords):
                state["base_move_type"] = (MOVE_TYPE_OPTIONS[0] if type_name == "ê°€ì •" and MOVE_TYPE_OPTIONS else
                                          (MOVE_TYPE_OPTIONS[1] if type_name == "ì‚¬ë¬´ì‹¤" and len(MOVE_TYPE_OPTIONS) > 1 else DEFAULT_MOVE_TYPE))
                part_index += 1; break
    
    if part_index < len(parts_after_phone):
        state["from_location"], state["from_floor"] = extract_floor_from_address(parts_after_phone[part_index]); part_index += 1
    else: return None, None, f"{line_number_display}ì¶œë°œì§€ ì£¼ì†Œ ì—†ìŒ (í•„ìˆ˜)"

    if part_index < len(parts_after_phone):
        state["to_location"], state["to_floor"] = extract_floor_from_address(parts_after_phone[part_index]); part_index += 1
    if part_index < len(parts_after_phone): state["special_notes"] = " ".join(parts_after_phone[part_index:])

    if not state.get("from_location"): return None, None, f"{line_number_display}ì¶œë°œì§€ ëˆ„ë½ (ì¬í™•ì¸)"
    return state, filename_phone_part + ".json", None

# --- ì—‘ì…€ ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ ---
COLUMN_ALIASES = {
    'moving_date': ['ë‚ ì§œ', 'ì´ì‚¬ë‚ ì§œ'], 'customer_name': ['ê³ ê°ëª…', 'ì´ë¦„', 'ì„±í•¨'],
    'customer_phone': ['ì „í™”ë²ˆí˜¸', 'ì—°ë½ì²˜', 'íœ´ëŒ€í°ë²ˆí˜¸', 'ì „í™”'], 'base_move_type': ['ì´ì‚¬ì¢…ë¥˜', 'êµ¬ë¶„'],
    'from_location': ['ì¶œë°œì§€ì£¼ì†Œ', 'ì¶œë°œì§€', 'ì¶œë°œ'], 'from_floor': ['ì¸µìˆ˜', 'ì¶œë°œì§€ ì¸µìˆ˜', 'ì¶œë°œì¸µìˆ˜'],
    'to_location': ['ë„ì°©ì§€ì£¼ì†Œ', 'ë„ì°©ì§€', 'ë„ì°©ì£¼ì†Œ'], 'to_floor': ['ë„ì°©ì§€ ì¸µìˆ˜', 'ë„ì°©ì¸µìˆ˜'],
    'special_notes': ['íŠ¹ì´ì‚¬í•­', 'ìš”êµ¬ì‚¬í•­', 'í¬ë§ì‚¬í•­', 'ê±´ì˜'],
}
def get_column_value(row, field_name, aliases, default=""):
    for alias in aliases.get(field_name, []):
        if alias in row.index and pd.notna(row[alias]): return str(row[alias]).strip()
    return default

def parse_excel_row_to_json(row, current_year, row_number_display=""):
    state = get_default_state()
    if row.isnull().all() or all(str(x).strip() == "" for x in row if pd.notna(x)):
        return None, None, f"{row_number_display}ë¹ˆ í–‰"

    moving_date_raw = get_column_value(row, 'moving_date', COLUMN_ALIASES)
    parsed_date_excel = parse_date_flexible(moving_date_raw, current_year)
    if parsed_date_excel: state["moving_date"] = parsed_date_excel

    customer_name_raw = get_column_value(row, 'customer_name', COLUMN_ALIASES)
    if customer_name_raw and customer_name_raw.lower() != "ë¯¸ì •": state["customer_name"] = customer_name_raw
    
    customer_phone_raw = get_column_value(row, 'customer_phone', COLUMN_ALIASES)
    if not customer_phone_raw: return None, None, f"{row_number_display}ì „í™”ë²ˆí˜¸ ì—†ìŒ"
    state["customer_phone"] = customer_phone_raw
    filename_phone_part = normalize_phone_number_for_filename(customer_phone_raw)
    if not filename_phone_part: return None, None, f"{row_number_display}ìœ íš¨í•˜ì§€ ì•Šì€ ì „í™”ë²ˆí˜¸"

    move_type_raw = get_column_value(row, 'base_move_type', COLUMN_ALIASES)
    if move_type_raw:
        move_type_char = move_type_raw.strip().lower()
        if any(keyword == move_type_char for keyword in MOVE_TYPE_KEYWORDS_TEXT["ê°€ì •"]): state["base_move_type"] = MOVE_TYPE_OPTIONS[0] if MOVE_TYPE_OPTIONS else DEFAULT_MOVE_TYPE
        elif any(keyword == move_type_char for keyword in MOVE_TYPE_KEYWORDS_TEXT["ì‚¬ë¬´ì‹¤"]): state["base_move_type"] = MOVE_TYPE_OPTIONS[1] if len(MOVE_TYPE_OPTIONS) > 1 else DEFAULT_MOVE_TYPE

    from_location_raw = get_column_value(row, 'from_location', COLUMN_ALIASES)
    if not from_location_raw: return None, None, f"{row_number_display}ì¶œë°œì§€ ì—†ìŒ"
    state["from_location"] = from_location_raw
    
    from_floor_raw = get_column_value(row, 'from_floor', COLUMN_ALIASES)
    if from_floor_raw: state["from_floor"] = "".join(filter(str.isdigit, from_floor_raw))
    else: _, state["from_floor"] = extract_floor_from_address(state["from_location"])

    to_location_raw = get_column_value(row, 'to_location', COLUMN_ALIASES)
    if to_location_raw: state["to_location"] = to_location_raw
    
    to_floor_raw = get_column_value(row, 'to_floor', COLUMN_ALIASES)
    if to_floor_raw: state["to_floor"] = "".join(filter(str.isdigit, to_floor_raw))
    elif state["to_location"]: _, state["to_floor"] = extract_floor_from_address(state["to_location"])

    state["special_notes"] = get_column_value(row, 'special_notes', COLUMN_ALIASES)
    
    if not state.get("from_location"): return None, None, f"{row_number_display}ì¶œë°œì§€ ëˆ„ë½ (ì¬í™•ì¸)"
    return state, filename_phone_part + ".json", None

# --- Streamlit UI ---
st.title("ì´ì‚¬ ì •ë³´ JSON ë³€í™˜") # ì œëª© ê°„ì†Œí™”
input_method = st.radio("ì…ë ¥ ë°©ì‹:", ('í…ìŠ¤íŠ¸', 'ì—‘ì…€ íŒŒì¼')) # ë¼ë””ì˜¤ ë²„íŠ¼ ë ˆì´ë¸” ê°„ì†Œí™”
text_input = ""
uploaded_file = None

if input_method == 'í…ìŠ¤íŠ¸':
    text_input = st.text_area("í…ìŠ¤íŠ¸ ì…ë ¥:", height=150, placeholder="ì—¬ê¸°ì— ì´ì‚¬ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”...") # placeholder ê°„ì†Œí™”, ë†’ì´ ì¡°ì ˆ
else: # ì—‘ì…€ íŒŒì¼
    uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "xls"], label_visibility="collapsed") # ë ˆì´ë¸” ìˆ¨ê¹€, íƒ€ì…ë§Œ í‘œì‹œ

if st.button("JSON ë³€í™˜ ë° Drive ì €ì¥"): # ë²„íŠ¼ ì´ë¦„ ìœ ì§€ (ê¸°ëŠ¥ ëª…ì‹œ)
    current_year = datetime.now(KST).year
    success_count = 0; error_count = 0; processed_items = 0; total_items = 0
    all_log_messages = []; items_to_process = []; is_excel = False
    
    st.sidebar.empty()
    results_container = st.empty(); progress_bar = st.progress(0)

    if input_method == 'í…ìŠ¤íŠ¸':
        if not text_input.strip(): st.warning("ì…ë ¥ ë‚´ìš© ì—†ìŒ")
        else: items_to_process = text_input.strip().split('\n'); total_items = len(items_to_process)
    elif input_method == 'ì—‘ì…€ íŒŒì¼':
        if uploaded_file is None: st.warning("íŒŒì¼ ì„ íƒ ì•ˆë¨")
        else:
            try:
                df = pd.read_excel(uploaded_file); df.columns = [str(col) for col in df.columns]
                items_to_process = [row for _, row in df.iterrows()]; total_items = len(items_to_process); is_excel = True
            except Exception as e: st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}"); items_to_process = []
    
    if not items_to_process and (text_input.strip() or uploaded_file): # ì…ë ¥ ì‹œë„ëŠ” ìˆì—ˆìœ¼ë‚˜ ì²˜ë¦¬í•  ì•„ì´í…œì´ ì—†ëŠ” ê²½ìš°
        st.info("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    elif items_to_process: # ì²˜ë¦¬í•  ì•„ì´í…œì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì•„ë˜ ë¡œì§ ì‹¤í–‰
        st.subheader("ì²˜ë¦¬ ê²°ê³¼") # ì´ subheaderëŠ” ìœ ì§€í•˜ëŠ” ê²ƒì´ ê²°ê³¼ êµ¬ë¶„ì— ì¢‹ìŒ
        for i, item_data in enumerate(items_to_process):
            processed_items += 1; identifier_prefix = ""; log_identifier = ""
            status_obj, filename, error_msg = (None, None, "ì•Œ ìˆ˜ ì—†ëŠ” ì…ë ¥")

            row_display_prefix = f"ì—‘ì…€ {i+1}í–‰" if is_excel else f"í…ìŠ¤íŠ¸ {i+1}ì¤„"

            if is_excel:
                cn_val = get_column_value(item_data, 'customer_name', COLUMN_ALIASES)
                cp_val = get_column_value(item_data, 'customer_phone', COLUMN_ALIASES)
                identifier_prefix = cp_val or cn_val or "" # ì „í™”ë²ˆí˜¸ ìš°ì„ 
                status_obj, filename, error_msg = parse_excel_row_to_json(item_data, current_year, f"{row_display_prefix}: ")
            else: 
                phone_match_log = PHONE_REGEX.search(item_data)
                if phone_match_log: identifier_prefix = phone_match_log.group(0)
                else: # ì „í™”ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš° (íŒŒì‹± í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì˜¤ë¥˜ ì²˜ë¦¬ë˜ê² ì§€ë§Œ, ë¡œê·¸ìš©ìœ¼ë¡œ ê°„ëµíˆ)
                    identifier_prefix = item_data[:20] # ì• 20ì ì •ë„ë§Œ

                status_obj, filename, error_msg = parse_line_to_json_flexible(item_data, current_year, f"{row_display_prefix}: ")

            progress_bar.progress(processed_items / total_items)
            # "ì²˜ë¦¬ ì¤‘..." ë©”ì‹œì§€ëŠ” ë„ˆë¬´ ìì£¼ ë°”ë€Œë¯€ë¡œ ì œê±°í•˜ê±°ë‚˜, ë§¤ìš° ê°„ê²°í•˜ê²Œ (ì˜ˆ: st.markdown(f"{processed_items}/{total_items}"))
            # results_container.markdown(f"{processed_items}/{total_items}") # ì´ ë¶€ë¶„ì€ ì£¼ì„ ì²˜ë¦¬í•˜ì—¬ ë” ê¹”ë”í•˜ê²Œ

            log_identifier = f"({identifier_prefix.strip()})" if identifier_prefix.strip() else ""

            if status_obj and filename:
                try:
                    save_result = gdrive.save_json_file(filename, status_obj) # ì‹¤ì œ ì €ì¥ ë¡œì§
                    if save_result and save_result.get('id'):
                        log_message = f"âœ… {filename} {log_identifier} (ID: {save_result.get('id')})" # ì„±ê³µ ë¡œê·¸ ê°„ì†Œí™”
                        all_log_messages.append(log_message); success_count += 1
                    else:
                        log_message = f"âŒ ì €ì¥ì‹¤íŒ¨: {filename} {log_identifier} (ì‘ë‹µ: {save_result})"
                        all_log_messages.append(log_message); error_count += 1
                except Exception as e:
                    log_message = f"âŒ ì˜¤ë¥˜: {filename if filename else 'ë°ì´í„°'} {log_identifier} ({str(e)})" # ì˜¤ë¥˜ ë¡œê·¸ ê°„ì†Œí™”
                    all_log_messages.append(log_message); error_count += 1
            else:
                log_message = f"âš ï¸ ê±´ë„ˆëœ€: {error_msg if error_msg else 'ì‚¬ìœ  ë¶ˆëª…'} {log_identifier}"
                all_log_messages.append(log_message); error_count +=1
        
        results_container.empty() # "ì²˜ë¦¬ ì¤‘" ë©”ì‹œì§€ ìµœì¢… ì œê±°
        # ìµœì¢… ìš”ì•½ ê°„ì†Œí™”
        st.info(f"ì´: {total_items} (ì‹œë„: {processed_items})")
        st.info(f"ì„±ê³µ: {success_count}")
        st.info(f"ì‹¤íŒ¨/ê±´ë„ˆëœ€: {error_count}")

        if all_log_messages:
            with st.expander("ìƒì„¸ ë¡œê·¸", expanded=error_count > 0): # ì˜¤ë¥˜ê°€ ìˆì„ ë•Œë§Œ ê¸°ë³¸ìœ¼ë¡œ í¼ì¹˜ê¸°
                for log_entry in all_log_messages:
                    color = "grey"; log_text = log_entry
                    if log_entry.startswith("âœ…"): color = "green"; log_text = log_entry.replace("âœ… ","")
                    elif log_entry.startswith("âŒ"): color = "red"; log_text = log_entry.replace("âŒ ","")
                    elif log_entry.startswith("âš ï¸"): color = "orange"; log_text = log_entry.replace("âš ï¸ ","")
                    st.markdown(f"<p style='color:{color}; margin-bottom:0; font-size:small;'>{log_text}</p>", unsafe_allow_html=True)