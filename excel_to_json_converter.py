# excel_to_json_converter.py
import streamlit as st
import json
import re
from datetime import datetime, date
import pytz
import pandas as pd

# í•„ìˆ˜ ëª¨ë“ˆ ë¡œë”©
try:
    import google_drive_helper as gdrive
    import data # data.pyì˜ METHOD_OPTIONS, DEFAULT_STORAGE_TYPE ë“±ì„ ìœ„í•¨
except ImportError as e:
    st.error(f"í•„ìˆ˜ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}. (google_drive_helper.py, data.py ë“±ì„ í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìœ„ì¹˜ì‹œì¼œì£¼ì„¸ìš”)")
    st.stop()

# ì‹œê°„ëŒ€ ì„¤ì •
try:
    KST = pytz.timezone("Asia/Seoul")
except pytz.UnknownTimeZoneError:
    st.warning("Asia/Seoul ì‹œê°„ëŒ€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ UTCë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‚ ì§œ ì²˜ë¦¬ì— ì˜í–¥ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    KST = pytz.utc

# ê¸°ë³¸ê°’ ì„¤ì •
DEFAULT_CUSTOMER_NAME = "ë¬´ëª…"
DEFAULT_MOVE_TYPE = data.MOVE_TYPE_OPTIONS[0] if hasattr(data, 'MOVE_TYPE_OPTIONS') and data.MOVE_TYPE_OPTIONS else "ê°€ì • ì´ì‚¬ ğŸ "
DEFAULT_STORAGE_TYPE = data.DEFAULT_STORAGE_TYPE if hasattr(data, 'DEFAULT_STORAGE_TYPE') else "ì»¨í…Œì´ë„ˆ ë³´ê´€ ğŸ“¦"
# ì‘ì—… ë°©ë²• ê¸°ë³¸ê°’ì€ parse_line_to_json_flexible í•¨ìˆ˜ ë‚´ì—ì„œ "ê³„ë‹¨ ğŸš¶"ìœ¼ë¡œ ì„¤ì •ë¨
DEFAULT_FROM_METHOD = data.METHOD_OPTIONS[0] if hasattr(data, 'METHOD_OPTIONS') and data.METHOD_OPTIONS else "ì‚¬ë‹¤ë¦¬ì°¨ ğŸªœ"
DEFAULT_TO_METHOD = data.METHOD_OPTIONS[0] if hasattr(data, 'METHOD_OPTIONS') and data.METHOD_OPTIONS else "ì‚¬ë‹¤ë¦¬ì°¨ ğŸªœ"
STAIR_METHOD_DEFAULT = "ê³„ë‹¨ ğŸš¶" # ìš”ì²­ëœ ê¸°ë³¸ ì‘ì—… ë°©ë²•

TODAY_ISO_DATE = datetime.now(KST).date().isoformat()

# --- ê³µí†µ í—¬í¼ í•¨ìˆ˜ ---
def parse_date_flexible(date_str_input, current_year):
    if isinstance(date_str_input, (datetime, date)):
        return date_str_input.strftime('%Y-%m-%d')
    if not date_str_input or str(date_str_input).strip().lower() == "ë¯¸ì •":
        return TODAY_ISO_DATE
    date_str = str(date_str_input).strip()
    date_str = re.split(r'\s+[0-9]{1,2}\s*[:ì‹œ]', date_str)[0].strip()
    patterns = [
        (r'(\d{4})\s*[-/ë…„\.]?\s*(\d{1,2})\s*[-/ì›”\.]?\s*(\d{1,2})\s*(ì¼?)', lambda m: (int(m.group(1)), int(m.group(2)), int(m.group(3)))),
        (r'(\d{1,2})\s*[-/ì›”\.]\s*(\d{1,2})\s*(ì¼?)', lambda m: (current_year, int(m.group(1)), int(m.group(2)))), # "06ì›” 30ì¼" ì²˜ë¦¬ ê°€ëŠ¥
        (r'(\d{2})\s*[-/ë…„\.]?\s*(\d{1,2})\s*[-/ì›”\.]?\s*(\d{1,2})\s*(ì¼?)', lambda m: (2000 + int(m.group(1)), int(m.group(2)), int(m.group(3))))
    ]
    for pattern, extractor in patterns:
        match = re.match(pattern, date_str)
        if match:
            try:
                year, month, day = extractor(match)
                # Ensure the matched part is the whole date string part
                if len(match.group(0).replace(" ","")) == len(date_str.replace(" ","")): # ê³µë°±ì œê±°í›„ ê¸¸ì´ë¹„êµ (ìœ ì—°ì„±)
                     return datetime(year, month, day).strftime('%Y-%m-%d')
            except ValueError:
                continue
    return TODAY_ISO_DATE

def normalize_phone_number_for_filename(phone_str):
    if not phone_str or not isinstance(phone_str, str): return None
    return "".join(filter(str.isdigit, phone_str))

def get_default_state():
    return {
        "moving_date": TODAY_ISO_DATE, "customer_name": DEFAULT_CUSTOMER_NAME, "customer_phone": "",
        "base_move_type": DEFAULT_MOVE_TYPE, "from_location": "", "to_location": "", "special_notes": "",
        "from_floor": "", "to_floor": "",
        "from_method": DEFAULT_FROM_METHOD, "to_method": DEFAULT_TO_METHOD,
        "is_storage_move": False, "storage_type": DEFAULT_STORAGE_TYPE,
        "apply_long_distance": False, "has_via_point": False,
        "deposit_amount": 0, "adjustment_amount": 0,
        "issue_tax_invoice": False, "card_payment": False, "remove_base_housewife": False,
        "dispatched_1t":0, "dispatched_2_5t":0, "dispatched_3_5t":0, "dispatched_5t":0,
        "sky_hours_from": 1, "sky_hours_final": 1,
        "waste_tons_input": 0.5, "has_waste_check": False,
        "uploaded_image_paths": [],
        "vehicle_select_radio": "ìë™ ì¶”ì²œ ì°¨ëŸ‰ ì‚¬ìš©", "manual_vehicle_select_value": None,
        "final_selected_vehicle": None, "recommended_vehicle_auto": None,
        "storage_duration": 1, "storage_use_electricity": False,
        "long_distance_selector": data.long_distance_options[0] if hasattr(data, 'long_distance_options') and data.long_distance_options else "ì„ íƒ ì•ˆ í•¨",
        "via_point_location": "", "via_point_method": DEFAULT_FROM_METHOD,
        "via_point_floor": "", "via_point_surcharge": 0,
        "regional_ladder_surcharge": 0,
        "date_opt_0_widget": False, "date_opt_1_widget": False, "date_opt_2_widget": False,
        "date_opt_3_widget": False, "date_opt_4_widget": False,
        "total_volume": 0.0, "total_weight": 0.0,
        "tab3_deposit_amount": 0, "tab3_adjustment_amount": 0, "tab3_regional_ladder_surcharge": 0,
        "tab3_date_opt_0_widget": False, "tab3_date_opt_1_widget": False, "tab3_date_opt_2_widget": False,
        "tab3_date_opt_3_widget": False, "tab3_date_opt_4_widget": False,
        "prev_final_selected_vehicle": None,
        "gdrive_search_term": "", "gdrive_search_results": [],
        "gdrive_file_options_map": {}, "gdrive_selected_filename": None, "gdrive_selected_file_id": None,
    }

def extract_floor_from_address_enhanced(address_str):
    if not address_str or not isinstance(address_str, str):
        return address_str if address_str else "", ""
    address_cleaned = address_str.strip()
    parsed_floor = ""
    address_part = address_cleaned
    ho_match = re.search(r'(\d+)\s*í˜¸(?!\d)', address_cleaned)
    if ho_match:
        ho_number_str = ho_match.group(1)
        if len(ho_number_str) > 2: parsed_floor = ho_number_str[:-2]
        elif len(ho_number_str) > 0: parsed_floor = ho_number_str # 1~2ìë¦¬ ìˆ«ìë©´ ê·¸ëŒ€ë¡œ ì¸µìˆ˜ë¡œ (ì˜ˆ: 52í˜¸ -> 52ì¸µ) - ì •ì±… ë³€ê²½ ì‹œ ìˆ˜ì •
        
        if parsed_floor: # "í˜¸" íŒ¨í„´ì—ì„œ ìœ íš¨í•œ ì¸µìˆ˜ íŒŒì‹± ì„±ê³µ ì‹œ
            address_part = address_cleaned[:ho_match.start(0)].strip()
            return address_part, parsed_floor
    
    floor_ending_match = re.search(r'^(.*?)(\s*(-?\d+)\s*(ì¸µ|F|f))$', address_cleaned, re.IGNORECASE)
    if floor_ending_match:
        address_part = floor_ending_match.group(1).strip()
        parsed_floor = floor_ending_match.group(3)
        return address_part, parsed_floor
    return address_cleaned, ""

# --- í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ (ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ ë°˜ì˜) ---
PHONE_REGEX_TEXT = re.compile(r'(01[016789]-?\d{3,4}-?\d{4}|0\d{1,2}-?\d{3,4}-?\d{4})')
MOVE_TYPE_KEYWORDS_TEXT = {"ê°€ì •": ["ê°€ì •", "ê°€"], "ì‚¬ë¬´ì‹¤": ["ì‚¬ë¬´ì‹¤", "ì‚¬"]}

def parse_line_to_json_flexible(line_text, current_year, line_number_display=""):
    state = get_default_state()
    original_line = line_text.strip()
    if not original_line: return None, None, f"{line_number_display}ë¹ˆ ì¤„"

    phone_match = PHONE_REGEX_TEXT.search(original_line)
    if not phone_match: return None, None, f"{line_number_display}ì „í™”ë²ˆí˜¸ ì—†ìŒ (í•„ìˆ˜)"
    state["customer_phone"] = phone_match.group(0).strip()
    filename_phone_part = normalize_phone_number_for_filename(state["customer_phone"])
    if not filename_phone_part: return None, None, f"{line_number_display}ìœ íš¨í•˜ì§€ ì•Šì€ ì „í™”ë²ˆí˜¸"

    text_before_phone = original_line[:phone_match.start()].strip()
    text_after_phone = original_line[phone_match.end():].strip()

    # 1. ë‚ ì§œ ë° ì´ë¦„ íŒŒì‹± (ì—°ë½ì²˜ ì•ë¶€ë¶„)
    parts_before_phone = [p.strip() for p in text_before_phone.split(maxsplit=2) if p.strip()] # ìµœëŒ€ 2~3ë©ì–´ë¦¬ë¡œ ì˜ˆìƒ (ë‚ ì§œ ì—¬ëŸ¬ë‹¨ì–´, ì´ë¦„)
                                                                                              # ì˜ˆ: "06ì›” 30ì¼", "ê¸ˆì§€ì›"
    
    date_found = False
    if parts_before_phone:
        # ë‚ ì§œê°€ ì—¬ëŸ¬ ë‹¨ì–´ì¼ ê°€ëŠ¥ì„± ê³ ë ¤ (ì˜ˆ: "06ì›” 30ì¼")
        # ì²«ë²ˆì§¸ íŒŒíŠ¸, ì²«ë²ˆì§¸+ë‘ë²ˆì§¸ íŒŒíŠ¸ë¥¼ ë‚ ì§œë¡œ ì‹œë„
        date_candidate_1 = parts_before_phone[0]
        parsed_date_1 = parse_date_flexible(date_candidate_1, current_year)

        if parsed_date_1 != TODAY_ISO_DATE or (parsed_date_1 == TODAY_ISO_DATE and date_candidate_1 and date_candidate_1.lower()!="ë¯¸ì •"):
            state["moving_date"] = parsed_date_1
            state["customer_name"] = " ".join(parts_before_phone[1:]) if len(parts_before_phone) > 1 else DEFAULT_CUSTOMER_NAME
            date_found = True
        elif len(parts_before_phone) > 1:
            date_candidate_2 = parts_before_phone[0] + " " + parts_before_phone[1]
            parsed_date_2 = parse_date_flexible(date_candidate_2, current_year)
            if parsed_date_2 != TODAY_ISO_DATE or (parsed_date_2 == TODAY_ISO_DATE and date_candidate_2 and date_candidate_2.lower()!="ë¯¸ì •"):
                state["moving_date"] = parsed_date_2
                state["customer_name"] = " ".join(parts_before_phone[2:]) if len(parts_before_phone) > 2 else DEFAULT_CUSTOMER_NAME
                date_found = True
    
    if not date_found: # ë‚ ì§œ ëª»ì°¾ìœ¼ë©´ ì „ì²´ë¥¼ ì´ë¦„ìœ¼ë¡œ, ë‚ ì§œëŠ” ì˜¤ëŠ˜
        state["customer_name"] = text_before_phone if text_before_phone else DEFAULT_CUSTOMER_NAME
        state["moving_date"] = TODAY_ISO_DATE
    
    if not state["customer_name"].strip(): # ì´ë¦„ íŒŒì‹± í›„ ë¹„ì—ˆìœ¼ë©´ ê¸°ë³¸ê°’
        state["customer_name"] = DEFAULT_CUSTOMER_NAME


    # 2. ì´ì‚¬ ì¢…ë¥˜, ì¶œë°œì§€, ë„ì°©ì§€, ë²„ë¦¬ëŠ” ê°’ íŒŒì‹± (ì—°ë½ì²˜ ë’·ë¶€ë¶„)
    # ì˜ˆì‹œ: "ê°€ ê´‘ì§„êµ¬ ê´‘ë‚˜ë£¨ë¡œ56ê¸¸ 29 6ë™ 1022í˜¸ ì†¡íŒŒêµ¬ ì ì‹¤ë™ ìˆ˜ 9ì‹œ-12ì‹œ"
    # ì£¼ìš” êµ¬ë¶„ìë¡œ 2ê°œ ì´ìƒì˜ ê³µë°± ë˜ëŠ” íƒ­ ì‚¬ìš©
    # (ì£¼ì†Œ ë‚´ì˜ ì¼ë°˜ ê³µë°±ì€ ìœ ì§€ ìœ„í•¨)
    
    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì£¼ìš” ë¸”ë¡ ë‚˜ëˆ„ê¸° (íƒ­ ë˜ëŠ” 2ê°œ ì´ìƒ ê³µë°± ê¸°ì¤€)
    # ìº¡ì²˜ ê·¸ë£¹ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ë¶„ì ìì²´ëŠ” ê²°ê³¼ì— í¬í•¨ë˜ì§€ ì•Šë„ë¡ í•¨ (None í•„í„°ë§ í•„ìš”)
    raw_parts_after_phone = re.split(r'\s{2,}|\t+', text_after_phone)
    parts_after_phone = [p.strip() for p in raw_parts_after_phone if p and p.strip()]

    if not parts_after_phone:
        return None, None, f"{line_number_display}ì´ì‚¬ ì¢…ë¥˜ ë° ì£¼ì†Œ ì •ë³´ ì—†ìŒ (í•„ìˆ˜)"

    # 2a. ì´ì‚¬ ì¢…ë¥˜ ("ê°€" ë˜ëŠ” "ì‚¬")
    if parts_after_phone[0].lower() == "ê°€":
        state["base_move_type"] = next((opt for opt in data.MOVE_TYPE_OPTIONS if "ê°€ì •" in opt), DEFAULT_MOVE_TYPE)
        parts_after_phone.pop(0)
    elif parts_after_phone[0].lower() == "ì‚¬":
        state["base_move_type"] = next((opt for opt in data.MOVE_TYPE_OPTIONS if "ì‚¬ë¬´ì‹¤" in opt), DEFAULT_MOVE_TYPE)
        parts_after_phone.pop(0)
    # else: ì´ì‚¬ì¢…ë¥˜ í‚¤ì›Œë“œ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ìœ ì§€

    if not parts_after_phone:
        return None, None, f"{line_number_display}ì¶œë°œì§€ ì£¼ì†Œ ì •ë³´ ì—†ìŒ (í•„ìˆ˜)"

    # 2b. ì¶œë°œì§€ ì£¼ì†Œ ë° ì¸µìˆ˜ ("...í˜¸"ë¡œ ëë‚¨)
    # ì—¬ëŸ¬ íŒŒíŠ¸ë¡œ ë‚˜ë‰˜ì—ˆì„ ìˆ˜ ìˆëŠ” ì£¼ì†Œë¥¼ "í˜¸"ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ë³‘í•©
    from_loc_str_parts = []
    from_loc_found = False
    for i, part in enumerate(parts_after_phone):
        from_loc_str_parts.append(part)
        current_from_loc_candidate = " ".join(from_loc_str_parts)
        ho_match = re.search(r'(\d+)í˜¸$', current_from_loc_candidate) # ë¬¸ìì—´ ëì´ "ìˆ«ì+í˜¸" ì¸ì§€
        if ho_match:
            ho_digits = ho_match.group(1)
            # ì£¼ì†Œ: "í˜¸" ì•ê¹Œì§€ ì „ì²´
            state["from_location"] = current_from_loc_candidate[:ho_match.start(0)].strip()
            # ì¸µìˆ˜: "í˜¸" ì• ìˆ«ìì—ì„œ ë’¤ 2ìë¦¬ ì œì™¸í•œ ì•ë¶€ë¶„
            if len(ho_digits) > 2:
                state["from_floor"] = ho_digits[:-2]
            else: # 2ìë¦¬ ì´í•˜ ìˆ«ìëŠ” ì¸µìˆ˜ ì •ë³´ë¡œ ë¶€ì í•© (ìš”ì²­ì‚¬í•­: "í˜¸ ì• ë‘ìë¦¬ë¥¼ ì œì™¸í•œ ì•ìë¦¬")
                state["from_floor"] = "" 
            
            parts_after_phone = parts_after_phone[i+1:] # ì‚¬ìš©ëœ ë¶€ë¶„ ì œê±°
            from_loc_found = True
            break
    
    if not from_loc_found:
        return None, None, f"{line_number_display}ì¶œë°œì§€ ì£¼ì†Œì—ì„œ '...í˜¸' íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # 2c. ë„ì°©ì§€ ì£¼ì†Œ (ë‚¨ì€ ë¶€ë¶„ ì¤‘ ì²«ë²ˆì§¸ íŒŒíŠ¸) ë° ì¸µìˆ˜
    # ë‚¨ì€ íŒŒíŠ¸ê°€ "ìš”ì¼ ì‹œê°„" ì •ë³´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜
    if parts_after_phone:
        # ë§ˆì§€ë§‰ íŒŒíŠ¸ê°€ "ìš”ì¼ ì‹œê°„" íŒ¨í„´ì¸ì§€ í™•ì¸
        # ì˜ˆ: "ìˆ˜ 9ì‹œ-12ì‹œ", "ì›”ìš”ì¼ 14:00", "10ì‹œ"
        # ë§¤ìš° ê°„ë‹¨í•œ íŒ¨í„´: ìš”ì¼ë¬¸ì(ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼)ë¡œ ì‹œì‘í•˜ê±°ë‚˜, ìˆ«ìë¡œ ì‹œì‘í•˜ê³  "ì‹œ"ë¡œ ëë‚˜ëŠ” ê²½ìš°
        last_part_candidate = parts_after_phone[-1]
        is_last_part_time_info = False
        if re.match(r'^[ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼]', last_part_candidate) or \
           (re.search(r'\d', last_part_candidate) and last_part_candidate.endswith('ì‹œ')):
            is_last_part_time_info = True

        if is_last_part_time_info:
            if len(parts_after_phone) > 1: # ì‹œê°„ ì •ë³´ ì™¸ì— ë‹¤ë¥¸ ë‚´ìš©ì´ ìˆìœ¼ë©´ ë„ì°©ì§€ë¡œ
                to_location_str = " ".join(parts_after_phone[:-1])
                state["to_location"], state["to_floor"] = extract_floor_from_address_enhanced(to_location_str)
            # else: ì‹œê°„ ì •ë³´ë§Œ ë‚¨ì•˜ìœ¼ë©´ ë„ì°©ì§€ ì—†ìŒ (ê¸°ë³¸ê°’ ìœ ì§€)
        else: # ë§ˆì§€ë§‰ íŒŒíŠ¸ê°€ ì‹œê°„ ì •ë³´ê°€ ì•„ë‹ˆë©´, ë‚¨ì€ ì „ì²´ë¥¼ ë„ì°©ì§€ë¡œ
            to_location_str = " ".join(parts_after_phone)
            state["to_location"], state["to_floor"] = extract_floor_from_address_enhanced(to_location_str)
            
    # 2d. ì‘ì—… ë°©ë²• ê¸°ë³¸ê°’ ì„¤ì •
    if hasattr(data, 'METHOD_OPTIONS') and STAIR_METHOD_DEFAULT in data.METHOD_OPTIONS:
        state["from_method"] = STAIR_METHOD_DEFAULT
        state["to_method"] = STAIR_METHOD_DEFAULT
    else: # "ê³„ë‹¨ ğŸš¶" ì˜µì…˜ì´ data.pyì— ì—†ì„ ê²½ìš°ì— ëŒ€í•œ ëŒ€ë¹„ (ê¸°ì¡´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        state["from_method"] = DEFAULT_FROM_METHOD # ë˜ëŠ” ë‹¤ë¥¸ ì ì ˆí•œ ì˜¤ë¥˜ ì²˜ë¦¬/ë¡œê¹…
        state["to_method"] = DEFAULT_TO_METHOD
        if 'special_notes' not in state or not state['special_notes']: state['special_notes'] = ""
        state['special_notes'] += " (ì°¸ê³ : ìš”ì²­ëœ 'ê³„ë‹¨' ì‘ì—…ë°©ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©)"


    # í•„ìˆ˜ í•­ëª© ìµœì¢… í™•ì¸
    if not state.get("from_location"):
        return None, None, f"{line_number_display}ì¶œë°œì§€ ì£¼ì†Œ ìµœì¢… íŒŒì‹± ì‹¤íŒ¨."
        
    return state, filename_phone_part + ".json", None


# --- ì—‘ì…€ ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ ---
COLUMN_ALIASES_EXCEL = {
    'moving_date': ['ë‚ ì§œ', 'ì´ì‚¬ë‚ ì§œ', 'ì¼ì'],
    'customer_name': ['ê³ ê°ëª…', 'ì´ë¦„', 'ì„±í•¨', 'ìƒí˜¸'],
    'customer_phone': ['ì „í™”ë²ˆí˜¸', 'ì—°ë½ì²˜', 'íœ´ëŒ€í°ë²ˆí˜¸', 'ì „í™”', 'í•¸ë“œí°', 'H.P', 'HP'],
    'base_move_type': ['ì´ì‚¬ì¢…ë¥˜', 'êµ¬ë¶„', 'ì¢…ë¥˜'],
    'from_location': ['ì¶œë°œì§€ì£¼ì†Œ', 'ì¶œë°œì§€', 'ì¶œë°œì£¼ì†Œ', 'ì¶œë°œ'],
    'from_floor': ['ì¸µìˆ˜', 'ì¶œë°œì§€ ì¸µìˆ˜', 'ì¶œë°œì¸µìˆ˜', 'ì¶œë°œ ì¸µ'],
    'to_location': ['ë„ì°©ì§€ì£¼ì†Œ', 'ë„ì°©ì§€', 'ë„ì°©ì£¼ì†Œ', 'ë„ì°©'],
    'to_floor': ['ë„ì°©ì§€ ì¸µìˆ˜', 'ë„ì°©ì¸µìˆ˜', 'ë„ì°© ì¸µ'],
    'special_notes': ['íŠ¹ì´ì‚¬í•­', 'ìš”êµ¬ì‚¬í•­', 'í¬ë§ì‚¬í•­', 'ê±´ì˜', 'ë©”ëª¨', 'ë¹„ê³ ', 'ì°¸ê³ ì‚¬í•­'],
}
def get_column_value(row, field_name, aliases, default=""):
    all_possible_names = [field_name.lower()] + [a.lower() for a in aliases.get(field_name, [])]
    row_index_lower = {str(idx_item).lower(): idx_item for idx_item in row.index}
    for alias_lower in all_possible_names:
        if alias_lower in row_index_lower and pd.notna(row[row_index_lower[alias_lower]]):
            return str(row[row_index_lower[alias_lower]]).strip()
    return default

def parse_excel_row_to_json(row, current_year, row_number_display=""):
    state = get_default_state()
    if row.isnull().all() or all(str(x).strip() == "" for x in row if pd.notna(x)):
        return None, None, f"{row_number_display}ë¹ˆ í–‰"

    moving_date_raw = get_column_value(row, 'moving_date', COLUMN_ALIASES_EXCEL)
    state["moving_date"] = parse_date_flexible(moving_date_raw, current_year)
    log_info_for_date = ""
    if moving_date_raw and moving_date_raw.strip().lower() != "ë¯¸ì •" and state["moving_date"] == TODAY_ISO_DATE:
        log_info_for_date = f"ì œê³µëœ ë‚ ì§œ '{moving_date_raw}'ê°€ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì²˜ë¦¬ë¨ (í˜•ì‹/ë‚´ìš© í™•ì¸ í•„ìš”)."


    customer_name_raw = get_column_value(row, 'customer_name', COLUMN_ALIASES_EXCEL)
    if customer_name_raw and customer_name_raw.lower() != "ë¯¸ì •":
        state["customer_name"] = customer_name_raw
    else: state["customer_name"] = DEFAULT_CUSTOMER_NAME
    if "ë³´ê´€" in state["customer_name"]:
        state["is_storage_move"] = True; state["storage_type"] = DEFAULT_STORAGE_TYPE

    customer_phone_raw = get_column_value(row, 'customer_phone', COLUMN_ALIASES_EXCEL)
    if not customer_phone_raw: return None, None, f"{row_number_display}ì „í™”ë²ˆí˜¸ ì—†ìŒ (í•„ìˆ˜)"
    state["customer_phone"] = customer_phone_raw
    filename_phone_part = normalize_phone_number_for_filename(customer_phone_raw)
    if not filename_phone_part: return None, None, f"{row_number_display}ìœ íš¨í•˜ì§€ ì•Šì€ ì „í™”ë²ˆí˜¸"

    move_type_raw = get_column_value(row, 'base_move_type', COLUMN_ALIASES_EXCEL)
    if move_type_raw:
        move_type_char = move_type_raw.strip().lower()
        if any(keyword == move_type_char for keyword in MOVE_TYPE_KEYWORDS_TEXT["ê°€ì •"]) or "ê°€ì •" in move_type_char:
            state["base_move_type"] = next((opt for opt in data.MOVE_TYPE_OPTIONS if "ê°€ì •" in opt), DEFAULT_MOVE_TYPE)
        elif any(keyword == move_type_char for keyword in MOVE_TYPE_KEYWORDS_TEXT["ì‚¬ë¬´ì‹¤"]) or "ì‚¬ë¬´ì‹¤" in move_type_char:
            state["base_move_type"] = next((opt for opt in data.MOVE_TYPE_OPTIONS if "ì‚¬ë¬´ì‹¤" in opt), DEFAULT_MOVE_TYPE)

    from_location_raw = get_column_value(row, 'from_location', COLUMN_ALIASES_EXCEL)
    if not from_location_raw: return None, None, f"{row_number_display}ì¶œë°œì§€ ì£¼ì†Œ ì—†ìŒ (í•„ìˆ˜)"
    from_floor_raw_col = get_column_value(row, 'from_floor', COLUMN_ALIASES_EXCEL)
    if from_floor_raw_col:
        state["from_floor"] = "".join(filter(str.isdigit, from_floor_raw_col))
        state["from_location"] = from_location_raw
    else:
        state["from_location"], state["from_floor"] = extract_floor_from_address_enhanced(from_location_raw)

    to_location_raw = get_column_value(row, 'to_location', COLUMN_ALIASES_EXCEL)
    to_floor_raw_col = get_column_value(row, 'to_floor', COLUMN_ALIASES_EXCEL)
    if to_location_raw or to_floor_raw_col:
        if to_floor_raw_col:
            state["to_floor"] = "".join(filter(str.isdigit, to_floor_raw_col))
            if to_location_raw: state["to_location"] = to_location_raw
        elif to_location_raw:
             state["to_location"], state["to_floor"] = extract_floor_from_address_enhanced(to_location_raw)

    state["special_notes"] = get_column_value(row, 'special_notes', COLUMN_ALIASES_EXCEL)
    if log_info_for_date and state["special_notes"]: state["special_notes"] = log_info_for_date + " " + state["special_notes"]
    elif log_info_for_date: state["special_notes"] = log_info_for_date


    if not state.get("from_location"):
        return None, None, f"{row_number_display}ì¶œë°œì§€ ëˆ„ë½ (ì¬í™•ì¸ í•„ìš”)"

    return state, filename_phone_part + ".json", None


# --- Streamlit UI ---
st.set_page_config(page_title="ì´ì‚¬ì •ë³´ JSON ë³€í™˜ê¸°", layout="wide")
st.title("ğŸšš ì´ì‚¬ ì •ë³´ JSON ë³€í™˜ ë° Drive ì €ì¥")
st.caption("í…ìŠ¤íŠ¸ ë˜ëŠ” Excel íŒŒì¼ë¡œ ëœ ì´ì‚¬ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ JSON íŒŒì¼ë¡œ ë³€í™˜í•˜ê³  Google Driveì— ì €ì¥í•©ë‹ˆë‹¤.")

input_method = st.radio("ì…ë ¥ ë°©ì‹ ì„ íƒ:", ('í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥', 'Excel íŒŒì¼ ì—…ë¡œë“œ'), horizontal=True)
text_input = ""
uploaded_file = None

if input_method == 'í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥':
    text_input = st.text_area("ì—¬ê¸°ì— ì´ì‚¬ ì •ë³´ë¥¼ í•œ ì¤„ì”© ì…ë ¥í•˜ì„¸ìš”:", height=200,
                              placeholder="ì˜ˆì‹œ: 06ì›” 30ì¼ ê¸ˆì§€ì› 010-2228-0418 ê°€ ê´‘ì§„êµ¬ ê´‘ë‚˜ë£¨ë¡œ56ê¸¸ 29 6ë™ 1022í˜¸ ì†¡íŒŒêµ¬ ì ì‹¤ë™ ìˆ˜ 9ì‹œ-12ì‹œ")
else:
    uploaded_file = st.file_uploader("ë³€í™˜í•  Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["xlsx", "xls"])
    st.markdown("""
    **Excel íŒŒì¼ í˜•ì‹ ê°€ì´ë“œ:**
    - ì²« ë²ˆì§¸ í–‰ì€ í—¤ë”(ì»¬ëŸ¼ëª…)ì—¬ì•¼ í•©ë‹ˆë‹¤.
    - **í•„ìˆ˜ ì»¬ëŸ¼**: `ì „í™”ë²ˆí˜¸`, `ì¶œë°œì§€ì£¼ì†Œ` (ë˜ëŠ” ìœ ì‚¬ì–´)
    - **ì„ íƒ ì»¬ëŸ¼**: `ë‚ ì§œ` (ì¸ì‹ ê°€ëŠ¥í•œ í˜•ì‹, ë¯¸ì…ë ¥/ì¸ì‹ë¶ˆê°€ ì‹œ ì˜¤ëŠ˜ ë‚ ì§œ), `ê³ ê°ëª…` (ë¯¸ì…ë ¥ì‹œ 'ë¬´ëª…'), `ì´ì‚¬ì¢…ë¥˜`('ê°€'/'ì‚¬' ë˜ëŠ” 'ê°€ì •', 'ì‚¬ë¬´ì‹¤'), `ì¶œë°œì§€ ì¸µìˆ˜`, `ë„ì°©ì§€ì£¼ì†Œ`, `ë„ì°©ì§€ ì¸µìˆ˜`, `íŠ¹ì´ì‚¬í•­` (ë˜ëŠ” ìœ ì‚¬ì–´)
    - ì¸µìˆ˜ëŠ” ì£¼ì†Œì—ì„œ "XXXí˜¸" ë˜ëŠ” "Nì¸µ" íŒ¨í„´ìœ¼ë¡œ ìë™ ì¸ì‹ ì‹œë„í•˜ë©°, ëª…ì‹œì  ì¸µìˆ˜ ì»¬ëŸ¼ì´ ìš°ì„ í•©ë‹ˆë‹¤. "XXXí˜¸"ì˜ ê²½ìš°, "í˜¸" ì•ë¶€ë¶„ì´ ì£¼ì†Œë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
    - ê³ ê°ëª…ì— "ë³´ê´€"ì´ í¬í•¨ë˜ë©´ ë³´ê´€ì´ì‚¬ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.
    """)

if st.button("ğŸ”„ JSON ë³€í™˜ ë° Google Driveì— ì €ì¥í•˜ê¸°"):
    current_year_for_parsing = datetime.now(KST).year
    success_count = 0; error_count = 0; processed_items = 0; total_items = 0
    all_log_messages = []; items_to_process = []; is_excel_input = False

    if input_method == 'í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥':
        if not text_input.strip(): st.warning("ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            items_to_process = [line for line in text_input.strip().split('\n') if line.strip()]
            total_items = len(items_to_process)
    elif input_method == 'Excel íŒŒì¼ ì—…ë¡œë“œ':
        is_excel_input = True
        if uploaded_file is None: st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            try:
                try: df = pd.read_excel(uploaded_file, engine='openpyxl')
                except Exception: uploaded_file.seek(0); df = pd.read_excel(uploaded_file, engine='xlrd')
                df.columns = [str(col).strip().lower() for col in df.columns] # ì»¬ëŸ¼ëª… ì†Œë¬¸ì ë³€í™˜ ë° ê³µë°± ì œê±°
                items_to_process = [row for _, row in df.iterrows() if not row.isnull().all()]
                total_items = len(items_to_process)
            except Exception as e: st.error(f"Excel íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); items_to_process = []

    if not items_to_process:
        if text_input.strip() or uploaded_file:
            st.info("ë³€í™˜í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        st.subheader("âœ¨ ì²˜ë¦¬ ê²°ê³¼")
        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, item_data_row_or_line in enumerate(items_to_process):
            processed_items += 1
            status_obj, filename, error_msg = (None, None, "ì•Œ ìˆ˜ ì—†ëŠ” ì…ë ¥ í˜•ì‹ ë˜ëŠ” ì²˜ë¦¬ ì˜¤ë¥˜")
            row_display_prefix = f"ì—‘ì…€ {df.index[i]+2}í–‰" if is_excel_input and hasattr(df, 'index') else (f"ì—‘ì…€ {i+2}í–‰" if is_excel_input else f"í…ìŠ¤íŠ¸ {i+1}ì¤„")

            if is_excel_input:
                status_obj, filename, error_msg = parse_excel_row_to_json(item_data_row_or_line, current_year_for_parsing, row_display_prefix + ": ")
            else: # í…ìŠ¤íŠ¸ ì…ë ¥
                status_obj, filename, error_msg = parse_line_to_json_flexible(item_data_row_or_line, current_year_for_parsing, row_display_prefix + ": ")

            status_text.text(f"ì²˜ë¦¬ ì¤‘... {processed_items}/{total_items} ({filename if filename else 'ë°ì´í„° ë¶„ì„ ì¤‘'})")
            progress_bar.progress(processed_items / total_items if total_items > 0 else 0)

            log_identifier_parts = []
            if status_obj and status_obj.get('customer_phone'): log_identifier_parts.append(status_obj['customer_phone'])
            if status_obj and status_obj.get('customer_name') != DEFAULT_CUSTOMER_NAME : log_identifier_parts.append(status_obj['customer_name'])
            log_identifier = f"({', '.join(log_identifier_parts)})" if log_identifier_parts else ""
            
            # ë‚ ì§œ ì²˜ë¦¬ ê´€ë ¨ ì •ë³´ ë¡œê·¸ì— ì¶”ê°€ (Excel ì…ë ¥ ì‹œ)
            if is_excel_input and status_obj and item_data_row_or_line is not None:
                moving_date_raw_excel = get_column_value(item_data_row_or_line, 'moving_date', COLUMN_ALIASES_EXCEL) # ì»¬ëŸ¼ëª… ì†Œë¬¸ìë¡œ ì¡°íšŒ
                if moving_date_raw_excel and moving_date_raw_excel.strip().lower() != "ë¯¸ì •" and status_obj.get("moving_date") == TODAY_ISO_DATE:
                    all_log_messages.append(f"â„¹ï¸ <span style='color:blue;'>ì •ë³´</span>: {row_display_prefix} ì œê³µëœ ë‚ ì§œ '{moving_date_raw_excel}'ê°€ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì²˜ë¦¬ë¨ (í˜•ì‹ ë˜ëŠ” ë‚´ìš© í™•ì¸ í•„ìš”). {filename if filename else ''} {log_identifier}")


            if status_obj and filename:
                final_state_to_save = get_default_state()
                final_state_to_save.update(status_obj) # íŒŒì‹±ëœ ë°ì´í„°ë¡œ ê¸°ë³¸ ìƒíƒœ ì—…ë°ì´íŠ¸
                # ë¶ˆí•„ìš”í•œ í‚¤ ì œê±° ë˜ëŠ” íŠ¹ì • í‚¤ë§Œ ì„ íƒí•˜ëŠ” ë¡œì§ì€ í˜„ì¬ ì—†ìŒ (ëª¨ë“  í‚¤ ì €ì¥)
                
                try:
                    gdrive_folder_id_secret = st.secrets.get("gcp_service_account", {}).get("drive_folder_id")
                    save_result = gdrive.save_json_file(filename, final_state_to_save, folder_id=gdrive_folder_id_secret)
                    if save_result and save_result.get('id'):
                        log_message = f"âœ”ï¸ <span style='color:green;'>ì €ì¥ ì„±ê³µ</span>: {filename} {log_identifier} (ID: {save_result.get('id')})"
                        all_log_messages.append(log_message); success_count += 1
                    else:
                        log_message = f"âŒ <span style='color:red;'>ì €ì¥ ì‹¤íŒ¨</span>: {filename} {log_identifier} (ì‘ë‹µ: {save_result})"
                        all_log_messages.append(log_message); error_count += 1
                except AttributeError as ae:
                     log_message = f"âŒ <span style='color:red;'>ì €ì¥ í•¨ìˆ˜ ì˜¤ë¥˜</span>: {filename} {log_identifier} (ì˜¤ë¥˜: {ae})"
                     all_log_messages.append(log_message); error_count += 1
                except Exception as e_save:
                    log_message = f"âŒ <span style='color:red;'>ì €ì¥ ì¤‘ ì˜ˆì™¸</span>: {filename if filename else 'ë°ì´í„°'} {log_identifier} ({str(e_save)})"
                    all_log_messages.append(log_message); error_count += 1
            else: # íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” í•„ìˆ˜ ì •ë³´ ëˆ„ë½
                log_message = f"âš ï¸ <span style='color:orange;'>ê±´ë„ˆëœ€/ì˜¤ë¥˜</span>: {error_msg if error_msg else 'ì‚¬ìœ  ë¶ˆëª…'} {log_identifier}"
                all_log_messages.append(log_message); error_count +=1

        status_text.empty(); progress_bar.empty()
        st.info(f"ì´ ë¶„ì„ ëŒ€ìƒ: {total_items} ê±´ (ì‹¤ì œ ì²˜ë¦¬ ì‹œë„: {processed_items} ê±´)")
        st.success(f"Google Drive ì €ì¥ ì„±ê³µ: {success_count} ê±´")
        if error_count > 0: st.error(f"ì‹¤íŒ¨ ë˜ëŠ” ê±´ë„ˆëœ€: {error_count} ê±´")
        else: st.info(f"ì‹¤íŒ¨ ë˜ëŠ” ê±´ë„ˆëœ€: {error_count} ê±´")

        if all_log_messages:
            expanded_log = (error_count > 0 or success_count < total_items or any("ì •ë³´" in log for log in all_log_messages))
            with st.expander("â–¼ ìƒì„¸ ì²˜ë¦¬ ë¡œê·¸ ë³´ê¸° (í´ë¦­)", expanded=expanded_log):
                log_html = "".join([f"<div style='font-size:small; margin-bottom:3px;'>{log}</div>" for log in all_log_messages])
                st.markdown(log_html, unsafe_allow_html=True)
