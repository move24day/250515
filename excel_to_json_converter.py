# excel_to_json_converter.py
import streamlit as st
import json
import re
from datetime import datetime, date
import pytz
import pandas as pd

# í•„ìˆ˜ ëª¨ë“ˆ ë¡œë”©
try:
    import google_drive_helper as gdrive
    import data # data.pyì˜ METHOD_OPTIONS, DEFAULT_STORAGE_TYPE ë“±ì„ ìœ„í•¨
    # state_manager ëª¨ë“ˆì—ì„œ STATE_KEYS_TO_SAVE, MOVE_TYPE_OPTIONSëŠ” í˜„ì¬ ì´ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
    # ë§Œì•½ í•´ë‹¹ ë³€ìˆ˜ë“¤ì´ í•„ìš”í•˜ë‹¤ë©´ ì£¼ì„ í•´ì œ ë˜ëŠ” data.py ë“±ì„ í†µí•´ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •
    # from state_manager import STATE_KEYS_TO_SAVE, MOVE_TYPE_OPTIONS
except ImportError as e:
    st.error(f"í•„ìˆ˜ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}. (google_drive_helper.py, data.py ë“±ì„ í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìœ„ì¹˜ì‹œì¼œì£¼ì„¸ìš”)")
    st.stop()

# ì‹œê°„ëŒ€ ì„¤ì •
try:
    KST = pytz.timezone("Asia/Seoul")
except pytz.UnknownTimeZoneError:
    st.warning("Asia/Seoul ì‹œê°„ëŒ€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ UTCë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‚ ì§œ ì²˜ë¦¬ì— ì˜í–¥ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    KST = pytz.utc

# ê¸°ë³¸ê°’ ì„¤ì •
DEFAULT_CUSTOMER_NAME = "ë¬´ëª…"
# MOVE_TYPE_OPTIONSëŠ” data.py ë˜ëŠ” ë‹¤ë¥¸ ì„¤ì • íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ì´ìƒì 
# ì—¬ê¸°ì„œëŠ” data.pyì— ì •ì˜ëœ ê²ƒì„ ì‚¬ìš©í•˜ë„ë¡ ê°€ì • (ì‹¤ì œ data.py êµ¬ì¡°ì— ë”°ë¼ ìˆ˜ì • í•„ìš”)
DEFAULT_MOVE_TYPE = data.MOVE_TYPE_OPTIONS[0] if hasattr(data, 'MOVE_TYPE_OPTIONS') and data.MOVE_TYPE_OPTIONS else "ê°€ì • ì´ì‚¬ ğŸ "
DEFAULT_STORAGE_TYPE = data.DEFAULT_STORAGE_TYPE if hasattr(data, 'DEFAULT_STORAGE_TYPE') else "ì»¨í…Œì´ë„ˆ ë³´ê´€ ğŸ“¦"
DEFAULT_FROM_METHOD = data.METHOD_OPTIONS[0] if hasattr(data, 'METHOD_OPTIONS') and data.METHOD_OPTIONS else "ì‚¬ë‹¤ë¦¬ì°¨ ğŸªœ"
DEFAULT_TO_METHOD = data.METHOD_OPTIONS[0] if hasattr(data, 'METHOD_OPTIONS') and data.METHOD_OPTIONS else "ì‚¬ë‹¤ë¦¬ì°¨ ğŸªœ"
TODAY_ISO_DATE = datetime.now(KST).date().isoformat()

# --- ê³µí†µ í—¬í¼ í•¨ìˆ˜ ---
def parse_date_flexible(date_str_input, current_year):
    """
    ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´ ë˜ëŠ” datetime ê°ì²´ë¥¼ YYYY-MM-DD í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì‹œê°„ ì •ë³´ëŠ” ì œê±°ë©ë‹ˆë‹¤. "ë¯¸ì •"ì´ê±°ë‚˜ ë¹ˆ ê°’ì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if isinstance(date_str_input, (datetime, date)): # ì´ë¯¸ datetime ë˜ëŠ” date ê°ì²´ì¸ ê²½ìš°
        return date_str_input.strftime('%Y-%m-%d')

    if not date_str_input or str(date_str_input).strip().lower() == "ë¯¸ì •":
        return TODAY_ISO_DATE # "ë¯¸ì •" ë˜ëŠ” ë¹ˆ ê°’ì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì„¤ì •
    
    date_str = str(date_str_input).strip()
    # ì‹œê°„ ì •ë³´ ì œê±° ì‹œë„ (ì˜ˆ: "5/10 14ì‹œ", "2024-05-10 14:00")
    date_str = re.split(r'\s+[0-9]{1,2}\s*[:ì‹œ]', date_str)[0].strip() # ê³µë°± í›„ ìˆ«ì + : ë˜ëŠ” ì‹œ
    
    patterns = [
        # YYYY-MM-DD, YYYY/MM/DD, YYYY.MM.DD, YYYYë…„ MMì›” DDì¼
        (r'(\d{4})\s*[-/ë…„\.]?\s*(\d{1,2})\s*[-/ì›”\.]?\s*(\d{1,2})\s*(ì¼?)', lambda m: (int(m.group(1)), int(m.group(2)), int(m.group(3)))),
        # MM-DD, MM/DD, MM.DD, MMì›” DDì¼ (í˜„ì¬ ì—°ë„ ì‚¬ìš©)
        (r'(\d{1,2})\s*[-/ì›”\.]\s*(\d{1,2})\s*(ì¼?)', lambda m: (current_year, int(m.group(1)), int(m.group(2)))),
        # YY-MM-DD, YY/MM/DD, YY.MM.DD (20YYë…„ìœ¼ë¡œ ê°„ì£¼)
        (r'(\d{2})\s*[-/ë…„\.]?\s*(\d{1,2})\s*[-/ì›”\.]?\s*(\d{1,2})\s*(ì¼?)', lambda m: (2000 + int(m.group(1)), int(m.group(2)), int(m.group(3))))
    ]

    for pattern, extractor in patterns:
        match = re.match(pattern, date_str)
        if match:
            # ë‚ ì§œ ë¬¸ìì—´ ì „ì²´ê°€ íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸ (ì˜ˆ: "5/10 ê°€" ë°©ì§€)
            # ì •ê·œì‹ì˜ `\s*(ì¼?)` ë“±ì´ ìˆì–´ ì¶”ê°€ í…ìŠ¤íŠ¸ê°€ ìˆì–´ë„ ë§¤ì¹˜ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
            # ë§¤ì¹˜ëœ ë¶€ë¶„ ì™¸ì— ë‹¤ë¥¸ ë¬¸ìê°€ ë‚¨ì•„ìˆëŠ”ì§€ í™•ì¸ í•„ìš”.
            # ì—¬ê¸°ì„œëŠ” íŒ¨í„´ ìì²´ê°€ ë‚ ì§œ ë¶€ë¶„ë§Œ ì •í™•íˆ ì»¤ë²„í•˜ë„ë¡ ê°€ì •.
            # ë§Œì•½ íŒ¨í„´ì´ "5/10"ê¹Œì§€ë§Œ ë§¤ì¹˜í•˜ê³  ë’¤ì— " ê°€"ê°€ ë‚¨ëŠ”ë‹¤ë©´,
            # date_str[len(match.group(0)):].strip() ìœ¼ë¡œ ë‚¨ì€ ë¶€ë¶„ì„ í™•ì¸í•  ìˆ˜ ìˆìŒ.
            # ì´ ì½”ë“œì—ì„œëŠ” ì¼ë‹¨ ë§¤ì¹˜ë˜ë©´ ë‚ ì§œë¡œ ê°„ì£¼.
            try:
                year, month, day = extractor(match)
                return datetime(year, month, day).strftime('%Y-%m-%d')
            except ValueError: # ì˜ëª»ëœ ë‚ ì§œ (ì˜ˆ: 2ì›” 30ì¼)
                continue
                
    return TODAY_ISO_DATE # ì–´ë–¤ íŒ¨í„´ê³¼ë„ ë§ì§€ ì•Šìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¡œ (ìš”ì²­ì— ë”°ë¼ None ë°˜í™˜ë„ ê°€ëŠ¥)

def normalize_phone_number_for_filename(phone_str):
    if not phone_str or not isinstance(phone_str, str): return None
    return "".join(filter(str.isdigit, phone_str))

def get_default_state():
    # state_manager.py ì™€ ìµœëŒ€í•œ ìœ ì‚¬í•˜ê²Œ ê¸°ë³¸ê°’ ì„¤ì • (í•„ìš”ì‹œ í•´ë‹¹ íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •)
    return {
        "moving_date": TODAY_ISO_DATE, "customer_name": DEFAULT_CUSTOMER_NAME, "customer_phone": "",
        "base_move_type": DEFAULT_MOVE_TYPE, "from_location": "", "to_location": "", "special_notes": "",
        "from_floor": "", "to_floor": "", 
        "from_method": DEFAULT_FROM_METHOD, 
        "to_method": DEFAULT_TO_METHOD,
        "is_storage_move": False, 
        "storage_type": DEFAULT_STORAGE_TYPE,
        # ... ê¸°íƒ€ í•„ìš”í•œ ëª¨ë“  í‚¤ì˜ ê¸°ë³¸ê°’ ì¶”ê°€ (state_manager.py ì°¸ê³ )
        "apply_long_distance": False, "has_via_point": False,
        "deposit_amount": 0, "adjustment_amount": 0, 
        "issue_tax_invoice": False, "card_payment": False, "remove_base_housewife": False,
        "dispatched_1t":0, "dispatched_2_5t":0, "dispatched_3_5t":0, "dispatched_5t":0,
        "sky_hours_from": 1, "sky_hours_final": 1,
        "waste_tons_input": 0.5, "has_waste_check": False,
        "uploaded_image_paths": [],
        "vehicle_select_radio": "ìë™ ì¶”ì²œ ì°¨ëŸ‰ ì‚¬ìš©", 
        "manual_vehicle_select_value": None,
        "final_selected_vehicle": None,
        "recommended_vehicle_auto": None,
        "storage_duration": 1, 
        "storage_use_electricity": False,
        "long_distance_selector": data.long_distance_options[0] if hasattr(data, 'long_distance_options') and data.long_distance_options else "ì„ íƒ ì•ˆ í•¨",
        "via_point_location": "",
        "via_point_method": DEFAULT_FROM_METHOD,
        "via_point_surcharge": 0,
        "regional_ladder_surcharge": 0,
        "date_opt_0_widget": False, "date_opt_1_widget": False, "date_opt_2_widget": False,
        "date_opt_3_widget": False, "date_opt_4_widget": False,
    }

def extract_floor_from_address_enhanced(address_str):
    """
    ì£¼ì†Œ ë¬¸ìì—´ì—ì„œ ì¸µìˆ˜ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    "XXXí˜¸" íŒ¨í„´ì˜ ê²½ìš°, ìˆ«ì ë’¤ 2ìë¦¬ë¥¼ ì œì™¸í•œ ì•ë¶€ë¶„ì„ ì¸µìˆ˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
    (ì˜ˆ: "1102í˜¸" -> 11ì¸µ, "302í˜¸" -> 3ì¸µ)
    "Nì¸µ" íŒ¨í„´ë„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    if not address_str or not isinstance(address_str, str):
        return address_str if address_str else "", ""

    address_cleaned = address_str.strip()
    floor_str = ""

    # íŒ¨í„´ 1: "XXXí˜¸" (ì˜ˆ: "1102í˜¸", "302 í˜¸")
    # "í˜¸" ë°”ë¡œ ì•ì˜ ìˆ«ì ì „ì²´ë¥¼ ìº¡ì²˜í•˜ê³ , "í˜¸" ë° ì•ë’¤ ê³µë°± ì œê±° ì‹œë„
    ho_match = re.search(r'(\d+)\s*í˜¸(?!\d)', address_cleaned) # "í˜¸" ë’¤ì— ìˆ«ìê°€ ì˜¤ì§€ ì•ŠëŠ” ê²½ìš° (ì˜ˆ: "101í˜¸í…”" ë°©ì§€)
    if ho_match:
        ho_number_str = ho_match.group(1) # "1102", "302"
        
        if len(ho_number_str) > 2 : # 3ìë¦¬ ì´ìƒ (ì˜ˆ: 302, 1102)
            floor_str = ho_number_str[:-2] # ë’¤ 2ìë¦¬ ì œì™¸ (302 -> 3, 1102 -> 11)
        elif len(ho_number_str) > 0 : # 1~2ìë¦¬ (ì˜ˆ: 52í˜¸, 2í˜¸) -> ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì˜ˆ: 52, 2) - ì´ ë¶€ë¶„ì€ ì •ì±…ì— ë”°ë¼ ë³€ê²½ ê°€ëŠ¥
             floor_str = ho_number_str
        # else: ìˆ«ìê°€ ì—†ìœ¼ë©´ floor_strì€ "" ìœ ì§€

        # ì£¼ì†Œì—ì„œ "XXXí˜¸" ë¶€ë¶„ ì œê±° ì‹œë„ (ë” ì •í™•í•˜ê²Œ)
        # ì£¼ì˜: "XXXí˜¸"ê°€ ì£¼ì†Œ ì¤‘ê°„ì— ìˆì„ ìˆ˜ë„ ìˆê³ , ëì— ìˆì„ ìˆ˜ë„ ìˆìŒ
        # address_cleaned = re.sub(r'\s*' + re.escape(ho_match.group(0)) + r'\s*', ' ', address_cleaned, 1).strip()
        # ìœ„ ë°©ì‹ì€ ë³µì¡í•˜ê³  ì˜¤ë¥˜ ê°€ëŠ¥ì„± ìˆìŒ. "XXXí˜¸"ë¥¼ í¬í•¨í•œ ì „ì²´ ë§¤ì¹˜ ë¶€ë¶„ì„ ì œê±°í•˜ëŠ” ê²ƒì´ ë” ì•ˆì „í•  ìˆ˜ ìˆìœ¼ë‚˜,
        # "XXXí˜¸"ê°€ í•­ìƒ ì£¼ì†Œì˜ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì´ ì•„ë‹ ìˆ˜ë„ ìˆìŒ (ì˜ˆ: ê±´ë¬¼ ì´ë¦„ ìì²´ê°€ "101í˜¸ ë¹Œë”©")
        # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ "í˜¸"ê¹Œì§€ë§Œ ë³´ê³  ì¸µìˆ˜ë¥¼ ì¶”ì¶œí•˜ê³ , ì£¼ì†ŒëŠ” ì›ë³¸ì—ì„œ í¬ê²Œ ë³€ê²½í•˜ì§€ ì•ŠëŠ” ë°©í–¥ìœ¼ë¡œ ì ‘ê·¼.
        # ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ "101ë™ 302í˜¸"ì—ì„œ "302í˜¸"ë¥¼ ì œê±°í•˜ê³  ì‹¶ë‹¤ë©´, í•´ë‹¹ ë¡œì§ ì¶”ê°€ í•„ìš”.
        # í˜„ì¬ëŠ” ì£¼ì†Œì—ì„œ "í˜¸" ê´€ë ¨ ë¶€ë¶„ì„ ì ê·¹ì ìœ¼ë¡œ ì œê±°í•˜ì§€ ì•ŠìŒ.
        # ë‹¤ë§Œ, "OOì•„íŒŒíŠ¸ 101ë™ 1102í˜¸" -> "OOì•„íŒŒíŠ¸ 101ë™ " ê³¼ ê°™ì´ ë’¤ì— ë¶™ì€ í˜¸ìˆ˜ë§Œ ì œê±°í•˜ëŠ” ì •ë„ëŠ” ê³ ë ¤ ê°€ëŠ¥
        
        # "XXXí˜¸"ê°€ ì£¼ì†Œ ëì— ëª…í™•íˆ ìˆì„ ë•Œë§Œ ì œê±°
        address_cleaned_temp = re.sub(r'\s+\d+\s*í˜¸$', '', address_cleaned) 
        if address_cleaned_temp != address_cleaned: # ì‹¤ì œë¡œ ì œê±°ê°€ ì¼ì–´ë‚¬ë‹¤ë©´
            address_cleaned = address_cleaned_temp.strip()
        
        # ì¶”ì¶œëœ ì¸µìˆ˜ê°€ ìˆìœ¼ë©´ ë°˜í™˜
        if floor_str:
            return address_cleaned, floor_str

    # íŒ¨í„´ 2: ì£¼ì†Œ ëì— "ìˆ«ì+ì¸µ/F/f" (ì˜ˆ: "OOë¹Œë”© 3ì¸µ", "XXì•„íŒŒíŠ¸ 10F")
    # ì´ íŒ¨í„´ì€ "í˜¸" íŒ¨í„´ë³´ë‹¤ ìš°ì„ ìˆœìœ„ê°€ ë‚®ì•„ì•¼ í•¨. ("101í˜¸ 3ì¸µ" ê°™ì€ ê²½ìš° "í˜¸"ì—ì„œ ë¨¼ì € ì²˜ë¦¬)
    floor_ending_match = re.search(r'^(.*?)(\s*(-?\d+)\s*(ì¸µ|F|f))$', address_cleaned, re.IGNORECASE)
    if floor_ending_match:
        address_part = floor_ending_match.group(1).strip()
        floor_num_part = floor_ending_match.group(3)
        return address_part, floor_num_part
        
    return address_cleaned, "" # ì–´ë–¤ íŒ¨í„´ì—ë„ í•´ë‹¹ ì—†ìœ¼ë©´, ì›ë˜ ì£¼ì†Œì™€ ë¹ˆ ì¸µìˆ˜ ë°˜í™˜

# --- í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ ---
PHONE_REGEX_TEXT = re.compile(r'(01[016789]-?\d{3,4}-?\d{4}|0\d{1,2}-?\d{3,4}-?\d{4})')
MOVE_TYPE_KEYWORDS_TEXT = {"ê°€ì •": ["ê°€ì •", "ê°€"], "ì‚¬ë¬´ì‹¤": ["ì‚¬ë¬´ì‹¤", "ì‚¬"]} # data.pyì˜ MOVE_TYPE_OPTIONS ì™€ ì—°ê³„ ê³ ë ¤

def parse_line_to_json_flexible(line_text, current_year, line_number_display=""):
    state = get_default_state() # ê¸°ë³¸ ìƒíƒœë¡œ ì´ˆê¸°í™”
    original_line = line_text.strip()
    if not original_line: return None, None, f"{line_number_display}ë¹ˆ ì¤„"

    # 1. ì „í™”ë²ˆí˜¸ íŒŒì‹± (í•„ìˆ˜)
    phone_match = PHONE_REGEX_TEXT.search(original_line)
    if not phone_match: return None, None, f"{line_number_display}ì „í™”ë²ˆí˜¸ ì—†ìŒ (í•„ìˆ˜)"
    state["customer_phone"] = phone_match.group(0)
    filename_phone_part = normalize_phone_number_for_filename(state["customer_phone"])
    if not filename_phone_part: return None, None, f"{line_number_display}ìœ íš¨í•˜ì§€ ì•Šì€ ì „í™”ë²ˆí˜¸"

    # ì „í™”ë²ˆí˜¸ ê¸°ì¤€ ì•/ë’¤ í…ìŠ¤íŠ¸ ë¶„ë¦¬
    before_phone = original_line[:phone_match.start()].strip()
    after_phone = original_line[phone_match.end():].strip()

    # 2. ì´ë¦„ ë° ë‚ ì§œ íŒŒì‹± (ì „í™”ë²ˆí˜¸ ì• ë¶€ë¶„)
    # ì´ë¦„ê³¼ ë‚ ì§œëŠ” ê³µë°± ë˜ëŠ” íƒ­ìœ¼ë¡œ êµ¬ë¶„ë  ìˆ˜ ìˆìŒ
    # ì˜ˆ: "í™ê¸¸ë™ 05/10", "05/10 í™ê¸¸ë™", "í™ê¸¸ë™", "05/10"
    parts_before_phone = [p.strip() for p in re.split(r'\s+|\t+', before_phone) if p.strip()] # ê³µë°± ë˜ëŠ” íƒ­ìœ¼ë¡œ ë¶„ë¦¬

    potential_name_parts = []
    date_found_in_before = False
    for part in parts_before_phone:
        parsed_date = parse_date_flexible(part, current_year) # YYYY-MM-DD í˜•ì‹ ë˜ëŠ” ì˜¤ëŠ˜ë‚ ì§œ ë°˜í™˜
        if parsed_date != TODAY_ISO_DATE or (parsed_date == TODAY_ISO_DATE and part.strip() != "" and part.strip().lower() !="ë¯¸ì •"): # ëª…ì‹œì  ë‚ ì§œ ì…ë ¥ìœ¼ë¡œ ê°„ì£¼
            # "ë¯¸ì •"ì´ë‚˜ ë¹ˆ ê°’ì´ ì•„ë‹Œë° ì˜¤ëŠ˜ ë‚ ì§œë¡œ íŒŒì‹±ëœ ê²½ìš°ëŠ”, ì‹¤ì œ ë‚ ì§œ ì…ë ¥ìœ¼ë¡œ ë´„.
            # ë˜ëŠ” ì˜¤ëŠ˜ì´ ì•„ë‹Œ ë‹¤ë¥¸ ë‚ ì§œë¡œ íŒŒì‹±ëœ ê²½ìš°.
            if not date_found_in_before : # ì²« ë²ˆì§¸ ìœ íš¨í•œ ë‚ ì§œë¥¼ ì´ì‚¬ ë‚ ì§œë¡œ ì„¤ì •
                 state["moving_date"] = parsed_date
                 date_found_in_before = True
            # else: ì—¬ëŸ¬ ë‚ ì§œê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ê²ƒë§Œ ì‚¬ìš© (ë˜ëŠ” ë‹¤ë¥¸ ë¡œì§ ì ìš© ê°€ëŠ¥)
        else: # ë‚ ì§œë¡œ íŒŒì‹±ë˜ì§€ ì•Šì€ ë¶€ë¶„ì€ ì´ë¦„ì˜ ì¼ë¶€ë¡œ ê°„ì£¼
            potential_name_parts.append(part)
    
    if potential_name_parts:
        state["customer_name"] = " ".join(potential_name_parts)
    else: # ì „í™”ë²ˆí˜¸ ì•ì— ì´ë¦„ ë¶€ë¶„ì´ ì—†ìœ¼ë©´
        state["customer_name"] = DEFAULT_CUSTOMER_NAME # ê¸°ë³¸ê°’ "ë¬´ëª…" ì‚¬ìš©

    if not date_found_in_before: # ì „í™”ë²ˆí˜¸ ì•ì—ì„œ ë‚ ì§œë¥¼ ëª» ì°¾ì•˜ìœ¼ë©´
        state["moving_date"] = TODAY_ISO_DATE # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì„¤ì •

    # ê³ ê°ëª…ì—ì„œ "ë³´ê´€" í‚¤ì›Œë“œ í™•ì¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    if "ë³´ê´€" in state["customer_name"]:
        state["is_storage_move"] = True
        state["storage_type"] = DEFAULT_STORAGE_TYPE

    # 3. ì´ì‚¬ ìœ í˜•, ì£¼ì†Œ, ë©”ëª¨ íŒŒì‹± (ì „í™”ë²ˆí˜¸ ë’· ë¶€ë¶„)
    # ì˜ˆ: "ê°€ ì„œìš¸ ê°•ë‚¨êµ¬ XXX 101ë™ 302í˜¸ ê²½ê¸° ìˆ˜ì›ì‹œ YYY 202ë™ 1102í˜¸ ì—ì–´ì»¨ ì´ì „ ì„¤ì¹˜"
    # ì˜ˆ: "ì‚¬ë¬´ì‹¤ ìš©ì‚°êµ¬ ... ì„±ë™êµ¬ ... íŒŒí‹°ì…˜ ë¶„í•´ì¡°ë¦½"
    # ì˜ˆ: "ì„œìš¸ ê°•ë‚¨êµ¬ XXX 101ë™ 302í˜¸" (ìœ í˜•, ë„ì°©ì§€, ë©”ëª¨ ìƒëµëœ ê²½ìš°)

    parts_after_phone = [p.strip() for p in re.split(r'\s{2,}|\t+', after_phone) if p.strip()] # 2ê°œ ì´ìƒ ê³µë°± ë˜ëŠ” íƒ­ìœ¼ë¡œ ë¶„ë¦¬
    if not parts_after_phone and after_phone: # ë¶„ë¦¬ë˜ì§€ ì•Šì•˜ì§€ë§Œ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì „ì²´ë¥¼ í•œ ë©ì–´ë¦¬ë¡œ
        parts_after_phone = [after_phone]
        
    part_idx = 0

    # ì´ì‚¬ ìœ í˜• ("ê°€", "ì‚¬") ë¨¼ì € ì²´í¬ (ì„ íƒì )
    if part_idx < len(parts_after_phone):
        current_part_lower = parts_after_phone[part_idx].lower()
        found_move_type_keyword = False
        for type_key_text, keywords_text in MOVE_TYPE_KEYWORDS_TEXT.items(): # ê°€ì •, ì‚¬ë¬´ì‹¤
            # í‚¤ì›Œë“œê°€ ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜, í‚¤ì›Œë“œë¡œ ì‹œì‘í•˜ê³  ë°”ë¡œ ë’¤ì— ë‹¤ë¥¸ ë‚´ìš©ì´ ì˜¤ëŠ” ê²½ìš°
            # (ì˜ˆ: "ê°€ ì„œìš¸...", "ì‚¬ë¬´ì‹¤ ìš©ì‚°...")
            for kw in keywords_text: # "ê°€ì •", "ê°€" ë˜ëŠ” "ì‚¬ë¬´ì‹¤", "ì‚¬"
                if current_part_lower == kw: # ì •í™•íˆ "ê°€" ë˜ëŠ” "ì‚¬ë¬´ì‹¤"
                    # data.pyì˜ MOVE_TYPE_OPTIONSì™€ ë§¤í•‘ (ì´ëª¨í‹°ì½˜ í¬í•¨ëœ ê°’ìœ¼ë¡œ)
                    if type_key_text == "ê°€ì •" and hasattr(data, 'MOVE_TYPE_OPTIONS') and data.MOVE_TYPE_OPTIONS:
                        state["base_move_type"] = next((opt for opt in data.MOVE_TYPE_OPTIONS if "ê°€ì •" in opt), DEFAULT_MOVE_TYPE)
                    elif type_key_text == "ì‚¬ë¬´ì‹¤" and hasattr(data, 'MOVE_TYPE_OPTIONS') and data.MOVE_TYPE_OPTIONS:
                        state["base_move_type"] = next((opt for opt in data.MOVE_TYPE_OPTIONS if "ì‚¬ë¬´ì‹¤" in opt), DEFAULT_MOVE_TYPE)
                    
                    parts_after_phone.pop(part_idx) # í•´ë‹¹ íŒŒíŠ¸ ì†Œëª¨ (ì¸ë±ìŠ¤ ì¡°ì • í•„ìš” ì—†ê²Œë”)
                    found_move_type_keyword = True
                    break 
                elif current_part_lower.startswith(kw + " ") and len(current_part_lower) > len(kw) + 1: # "ê°€ ì„œìš¸..."
                    if type_key_text == "ê°€ì •" and hasattr(data, 'MOVE_TYPE_OPTIONS') and data.MOVE_TYPE_OPTIONS:
                        state["base_move_type"] = next((opt for opt in data.MOVE_TYPE_OPTIONS if "ê°€ì •" in opt), DEFAULT_MOVE_TYPE)
                    elif type_key_text == "ì‚¬ë¬´ì‹¤" and hasattr(data, 'MOVE_TYPE_OPTIONS') and data.MOVE_TYPE_OPTIONS:
                        state["base_move_type"] = next((opt for opt in data.MOVE_TYPE_OPTIONS if "ì‚¬ë¬´ì‹¤" in opt), DEFAULT_MOVE_TYPE)

                    parts_after_phone[part_idx] = parts_after_phone[part_idx][len(kw):].strip() # í‚¤ì›Œë“œ ì œê±° í›„ ë‚¨ì€ ë¶€ë¶„ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                    found_move_type_keyword = True
                    break
            if found_move_type_keyword:
                break 
        # ì´ì‚¬ ìœ í˜• í‚¤ì›Œë“œê°€ ì²« íŒŒíŠ¸ì— ì—†ì—ˆìœ¼ë©´, part_idxëŠ” ê·¸ëŒ€ë¡œ 0, parts_after_phoneë„ ê·¸ëŒ€ë¡œ.

    # ì¶œë°œì§€ ì£¼ì†Œ ë° ì¸µìˆ˜ (í•„ìˆ˜)
    if part_idx < len(parts_after_phone):
        from_loc_raw = parts_after_phone[part_idx]
        state["from_location"], state["from_floor"] = extract_floor_from_address_enhanced(from_loc_raw)
        part_idx += 1
    else: # ì „í™”ë²ˆí˜¸ ë’¤ì— ì•„ë¬´ ë‚´ìš©ë„ ì—†ìœ¼ë©´ ì¶œë°œì§€ ëˆ„ë½
        if not state.get("from_location"): # í˜¹ì‹œ ë‹¤ë¥¸ ê²½ë¡œë¡œ ì´ë¯¸ ì±„ì›Œì§€ì§€ ì•Šì•˜ë‹¤ë©´
             return None, None, f"{line_number_display}ì¶œë°œì§€ ì£¼ì†Œ ì—†ìŒ (í•„ìˆ˜)"


    # ë„ì°©ì§€ ì£¼ì†Œ ë° ì¸µìˆ˜ (ì„ íƒì )
    if part_idx < len(parts_after_phone):
        # ë‹¤ìŒ íŒŒíŠ¸ê°€ ë„ì°©ì§€ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆëŠ”ì§€? (ì˜ˆ: íŠ¹ì • í‚¤ì›Œë“œ, ë˜ëŠ” ë‹¨ìˆœíˆ ë‹¤ìŒ ì£¼ì†Œ í˜•íƒœ)
        # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ ë‹¤ìŒ íŒŒíŠ¸ë¥¼ ë„ì°©ì§€ë¡œ ê°„ì£¼.
        # ë§Œì•½ ë‹¤ìŒ íŒŒíŠ¸ê°€ ëª…ë°±íˆ ë©”ëª¨ì²˜ëŸ¼ ë³´ì´ë©´ (ì˜ˆ: "ì—ì–´ì»¨", "ì¡°ë¦½") ë„ì°©ì§€ëŠ” ì—†ëŠ” ê²ƒìœ¼ë¡œ ì²˜ë¦¬í•´ì•¼ í•¨.
        # ê°„ë‹¨í•˜ê²ŒëŠ”, ë‚¨ì€ íŒŒíŠ¸ê°€ 1ê°œ ì´ˆê³¼ì¼ ë•Œë§Œ ë‘ ë²ˆì§¸ë¥¼ ë„ì°©ì§€ë¡œ ë³¼ ìˆ˜ë„ ìˆìŒ.
        # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ ìˆœì„œëŒ€ë¡œ í• ë‹¹.
        to_loc_raw = parts_after_phone[part_idx]
        # ë„ì°©ì§€ê°€ ë  ìˆ˜ ì—†ëŠ” í‚¤ì›Œë“œ ì˜ˆì‹œ (ì´ëŸ° ê²½ìš° ë©”ëª¨ë¡œ ë„˜ê¹€)
        skip_keywords_for_to_location = ["ì—ì–´ì»¨", "ì¥ë¡±", "ì¡°ë¦½", "ì´ì „", "ì„¤ì¹˜", "ë³´ê´€", "íê¸°"] # ë” ì¶”ê°€ ê°€ëŠ¥
        if not any(keyword in to_loc_raw for keyword in skip_keywords_for_to_location):
            state["to_location"], state["to_floor"] = extract_floor_from_address_enhanced(to_loc_raw)
            part_idx += 1
        # else: ë„ì°©ì§€ë¡œ ë³´ì´ì§€ ì•Šìœ¼ë©´, ì´ íŒŒíŠ¸ëŠ” ì•„ë˜ ë©”ëª¨ë¡œ í•©ì³ì§.
    
    # íŠ¹ì´ì‚¬í•­ (ë‚˜ë¨¸ì§€ ë¶€ë¶„)
    if part_idx < len(parts_after_phone):
        state["special_notes"] = " ".join(parts_after_phone[part_idx:])

    # ìµœì¢… ì¶œë°œì§€ í™•ì¸
    if not state.get("from_location"): # ë‹¤ì‹œ í•œë²ˆ ì¶œë°œì§€ í•„ìˆ˜ í™•ì¸
        return None, None, f"{line_number_display}ì¶œë°œì§€ ëˆ„ë½ (ì¬í™•ì¸ í•„ìš”)"
        
    return state, filename_phone_part + ".json", None


# --- ì—‘ì…€ ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ ---
COLUMN_ALIASES_EXCEL = {
    'moving_date': ['ë‚ ì§œ', 'ì´ì‚¬ë‚ ì§œ'], 
    'customer_name': ['ê³ ê°ëª…', 'ì´ë¦„', 'ì„±í•¨'],
    'customer_phone': ['ì „í™”ë²ˆí˜¸', 'ì—°ë½ì²˜', 'íœ´ëŒ€í°ë²ˆí˜¸', 'ì „í™”', 'í•¸ë“œí°'], 
    'base_move_type': ['ì´ì‚¬ì¢…ë¥˜', 'êµ¬ë¶„'], # 'ê°€', 'ì‚¬' ë˜ëŠ” "ê°€ì •ì´ì‚¬", "ì‚¬ë¬´ì‹¤ì´ì‚¬" ë“±
    'from_location': ['ì¶œë°œì§€ì£¼ì†Œ', 'ì¶œë°œì§€', 'ì¶œë°œ'], 
    'from_floor': ['ì¸µìˆ˜', 'ì¶œë°œì§€ ì¸µìˆ˜', 'ì¶œë°œì¸µìˆ˜', 'ì¶œë°œ ì¸µ'], # 'ì¶œë°œ ì¸µ' ì¶”ê°€
    'to_location': ['ë„ì°©ì§€ì£¼ì†Œ', 'ë„ì°©ì§€', 'ë„ì°©ì£¼ì†Œ', 'ë„ì°©'], 
    'to_floor': ['ë„ì°©ì§€ ì¸µìˆ˜', 'ë„ì°©ì¸µìˆ˜', 'ë„ì°© ì¸µ'], # 'ë„ì°© ì¸µ' ì¶”ê°€
    'special_notes': ['íŠ¹ì´ì‚¬í•­', 'ìš”êµ¬ì‚¬í•­', 'í¬ë§ì‚¬í•­', 'ê±´ì˜', 'ë©”ëª¨', 'ë¹„ê³ '], # 'ë©”ëª¨', 'ë¹„ê³ ' ì¶”ê°€
}
def get_column_value(row, field_name, aliases, default=""):
    # field_name ìì²´ë„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ê°„ì£¼
    all_possible_names = [field_name] + aliases.get(field_name, [])
    for alias in all_possible_names:
        if alias in row.index and pd.notna(row[alias]):
            return str(row[alias]).strip()
    return default

def parse_excel_row_to_json(row, current_year, row_number_display=""):
    state = get_default_state()
    if row.isnull().all() or all(str(x).strip() == "" for x in row if pd.notna(x)):
        return None, None, f"{row_number_display}ë¹ˆ í–‰"

    # ë‚ ì§œ
    moving_date_raw = get_column_value(row, 'moving_date', COLUMN_ALIASES_EXCEL)
    state["moving_date"] = parse_date_flexible(moving_date_raw, current_year) # ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ë°˜í™˜

    # ê³ ê°ëª…
    customer_name_raw = get_column_value(row, 'customer_name', COLUMN_ALIASES_EXCEL)
    if customer_name_raw and customer_name_raw.lower() != "ë¯¸ì •":
        state["customer_name"] = customer_name_raw
    else: # ì´ë¦„ì´ ì—†ê±°ë‚˜ "ë¯¸ì •"ì´ë©´
        state["customer_name"] = DEFAULT_CUSTOMER_NAME
    
    if "ë³´ê´€" in state["customer_name"]: # ê³ ê°ëª…ì— "ë³´ê´€" ìˆìœ¼ë©´ ë³´ê´€ì´ì‚¬ ì²˜ë¦¬
        state["is_storage_move"] = True
        state["storage_type"] = DEFAULT_STORAGE_TYPE

    # ì „í™”ë²ˆí˜¸ (í•„ìˆ˜)
    customer_phone_raw = get_column_value(row, 'customer_phone', COLUMN_ALIASES_EXCEL)
    if not customer_phone_raw: return None, None, f"{row_number_display}ì „í™”ë²ˆí˜¸ ì—†ìŒ (í•„ìˆ˜)"
    state["customer_phone"] = customer_phone_raw
    filename_phone_part = normalize_phone_number_for_filename(customer_phone_raw)
    if not filename_phone_part: return None, None, f"{row_number_display}ìœ íš¨í•˜ì§€ ì•Šì€ ì „í™”ë²ˆí˜¸"

    # ì´ì‚¬ ì¢…ë¥˜
    move_type_raw = get_column_value(row, 'base_move_type', COLUMN_ALIASES_EXCEL)
    if move_type_raw:
        move_type_char = move_type_raw.strip().lower()
        # data.pyì˜ MOVE_TYPE_OPTIONS (ì´ëª¨í‹°ì½˜ í¬í•¨ëœ ì›ë³¸)ê³¼ ë§¤í•‘
        if any(keyword == move_type_char for keyword in MOVE_TYPE_KEYWORDS_TEXT["ê°€ì •"]) or "ê°€ì •" in move_type_char:
            state["base_move_type"] = next((opt for opt in data.MOVE_TYPE_OPTIONS if "ê°€ì •" in opt), DEFAULT_MOVE_TYPE) if hasattr(data, 'MOVE_TYPE_OPTIONS') else DEFAULT_MOVE_TYPE
        elif any(keyword == move_type_char for keyword in MOVE_TYPE_KEYWORDS_TEXT["ì‚¬ë¬´ì‹¤"]) or "ì‚¬ë¬´ì‹¤" in move_type_char:
            state["base_move_type"] = next((opt for opt in data.MOVE_TYPE_OPTIONS if "ì‚¬ë¬´ì‹¤" in opt), DEFAULT_MOVE_TYPE) if hasattr(data, 'MOVE_TYPE_OPTIONS') else DEFAULT_MOVE_TYPE
        # else: ì¼ì¹˜í•˜ëŠ” ìœ í˜• ì—†ìœ¼ë©´ ê¸°ë³¸ê°’(state ì´ˆê¸°ê°’) ìœ ì§€

    # ì¶œë°œì§€ ì£¼ì†Œ (í•„ìˆ˜) ë° ì¸µìˆ˜
    from_location_raw = get_column_value(row, 'from_location', COLUMN_ALIASES_EXCEL)
    if not from_location_raw: return None, None, f"{row_number_display}ì¶œë°œì§€ ì£¼ì†Œ ì—†ìŒ (í•„ìˆ˜)"
    
    from_floor_raw_col = get_column_value(row, 'from_floor', COLUMN_ALIASES_EXCEL) # ì—‘ì…€ì˜ ëª…ì‹œì  ì¸µìˆ˜ ì»¬ëŸ¼
    if from_floor_raw_col:
        state["from_floor"] = "".join(filter(str.isdigit, from_floor_raw_col)) # ìˆ«ìë§Œ ì¶”ì¶œ
        state["from_location"] = from_location_raw # ì£¼ì†Œë„ í•¨ê»˜ ì €ì¥
    else: # ëª…ì‹œì  ì¸µìˆ˜ ì»¬ëŸ¼ ì—†ìœ¼ë©´ ì£¼ì†Œì—ì„œ ì¶”ì¶œ ì‹œë„
        state["from_location"], state["from_floor"] = extract_floor_from_address_enhanced(from_location_raw)

    # ë„ì°©ì§€ ì£¼ì†Œ ë° ì¸µìˆ˜ (ì„ íƒì )
    to_location_raw = get_column_value(row, 'to_location', COLUMN_ALIASES_EXCEL)
    to_floor_raw_col = get_column_value(row, 'to_floor', COLUMN_ALIASES_EXCEL) # ì—‘ì…€ì˜ ëª…ì‹œì  ì¸µìˆ˜ ì»¬ëŸ¼
    if to_location_raw or to_floor_raw_col : # ë„ì°©ì§€ ì£¼ì†Œë‚˜ ì¸µìˆ˜ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì²˜ë¦¬
        if to_floor_raw_col:
            state["to_floor"] = "".join(filter(str.isdigit, to_floor_raw_col))
            if to_location_raw: state["to_location"] = to_location_raw
        elif to_location_raw: # ì¸µìˆ˜ ì»¬ëŸ¼ì€ ì—†ì§€ë§Œ ì£¼ì†ŒëŠ” ìˆì„ ë•Œ
            state["to_location"], state["to_floor"] = extract_floor_from_address_enhanced(to_location_raw)
    
    # íŠ¹ì´ì‚¬í•­
    state["special_notes"] = get_column_value(row, 'special_notes', COLUMN_ALIASES_EXCEL)
    
    # ìµœì¢… ì¶œë°œì§€ í™•ì¸
    if not state.get("from_location"):
        return None, None, f"{row_number_display}ì¶œë°œì§€ ëˆ„ë½ (ì¬í™•ì¸ í•„ìš”)"
        
    return state, filename_phone_part + ".json", None


# --- Streamlit UI ---
st.set_page_config(page_title="ì´ì‚¬ì •ë³´ JSON ë³€í™˜ê¸°", layout="wide") # ì˜¤íƒ€ ìˆ˜ì •: ì´ì‚¬ê²¬ì  -> ì´ì‚¬ì •ë³´
st.title("ğŸšš ì´ì‚¬ ì •ë³´ JSON ë³€í™˜ ë° Drive ì €ì¥")
st.caption("í…ìŠ¤íŠ¸ ë˜ëŠ” Excel íŒŒì¼ë¡œ ëœ ì´ì‚¬ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ JSON íŒŒì¼ë¡œ ë³€í™˜í•˜ê³  Google Driveì— ì €ì¥í•©ë‹ˆë‹¤.")

input_method = st.radio("ì…ë ¥ ë°©ì‹ ì„ íƒ:", ('í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥', 'Excel íŒŒì¼ ì—…ë¡œë“œ'), horizontal=True)
text_input = ""
uploaded_file = None

if input_method == 'í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥':
    text_input = st.text_area("ì—¬ê¸°ì— ì´ì‚¬ ì •ë³´ë¥¼ í•œ ì¤„ì”© ì…ë ¥í•˜ì„¸ìš”:", height=200, 
                              placeholder="ì˜ˆì‹œ: í™ê¸¸ë™ 010-1234-5678 5/10 ê°€ ì„œìš¸ ê°•ë‚¨êµ¬ XXX 101ë™ 302í˜¸ ê²½ê¸° ìˆ˜ì›ì‹œ YYY 202ë™ 1102í˜¸ ì—ì–´ì»¨ ì´ì „ ì„¤ì¹˜\në˜ëŠ”: 010-9876-5432 ê°•ë‚¨ ì•„íŒŒíŠ¸ 102ë™ 1501í˜¸ ìš©ì¸ ë¹Œë¼ 303í˜¸ 5/12")
else: # Excel íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ë³€í™˜í•  Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["xlsx", "xls"])
    st.markdown("""
    **Excel íŒŒì¼ í˜•ì‹ ê°€ì´ë“œ:**
    - ì²« ë²ˆì§¸ í–‰ì€ í—¤ë”(ì»¬ëŸ¼ëª…)ì—¬ì•¼ í•©ë‹ˆë‹¤.
    - í•„ìˆ˜ ì»¬ëŸ¼: `ì „í™”ë²ˆí˜¸`, `ì¶œë°œì§€ì£¼ì†Œ` (ë˜ëŠ” `ì¶œë°œì§€`, `ì¶œë°œ` ë“± ìœ ì‚¬ì–´)
    - ì„ íƒ ì»¬ëŸ¼: `ë‚ ì§œ`, `ê³ ê°ëª…`, `ì´ì‚¬ì¢…ë¥˜`('ê°€' ë˜ëŠ” 'ì‚¬', ë˜ëŠ” "ê°€ì • ì´ì‚¬", "ì‚¬ë¬´ì‹¤ ì´ì‚¬"), `ì¶œë°œì§€ ì¸µìˆ˜`, `ë„ì°©ì§€ì£¼ì†Œ`, `ë„ì°©ì§€ ì¸µìˆ˜`, `íŠ¹ì´ì‚¬í•­` (ë˜ëŠ” `ë©”ëª¨`, `ë¹„ê³ ` ë“± ìœ ì‚¬ì–´)
    - ì¸µìˆ˜ëŠ” ì£¼ì†Œì—ì„œ "XXXí˜¸" íŒ¨í„´(ì˜ˆ: "ê°•ë‚¨ì•„íŒŒíŠ¸ 101ë™ 302í˜¸" -> 3ì¸µ) ë˜ëŠ” "Nì¸µ" íŒ¨í„´ìœ¼ë¡œ ìë™ì¸ì‹ ì‹œë„. ëª…ì‹œì  ì¸µìˆ˜ ì»¬ëŸ¼ì´ ìš°ì„ í•©ë‹ˆë‹¤.
    - ê³ ê°ëª…ì— "ë³´ê´€"ì´ í¬í•¨ë˜ë©´ ë³´ê´€ì´ì‚¬ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
    - ë‚ ì§œê°€ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œ, ê³ ê°ëª…ì´ ì—†ìœ¼ë©´ "ë¬´ëª…"ìœ¼ë¡œ ìë™ ì…ë ¥ë©ë‹ˆë‹¤.
    """)

if st.button("ğŸ”„ JSON ë³€í™˜ ë° Google Driveì— ì €ì¥í•˜ê¸°"):
    current_year_for_parsing = datetime.now(KST).year # parse_date_flexibleì— ì „ë‹¬ë  í˜„ì¬ ì—°ë„
    success_count = 0; error_count = 0; processed_items = 0; total_items = 0
    all_log_messages = []; items_to_process = []; is_excel_input = False # ë³€ìˆ˜ëª… ë³€ê²½
    
    if input_method == 'í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥':
        if not text_input.strip():
            st.warning("ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            items_to_process = [line for line in text_input.strip().split('\n') if line.strip()]
            total_items = len(items_to_process)
    elif input_method == 'Excel íŒŒì¼ ì—…ë¡œë“œ':
        is_excel_input = True # Excel ì…ë ¥ì„ì„ í‘œì‹œ
        if uploaded_file is None:
            st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            try:
                try: df = pd.read_excel(uploaded_file, engine='openpyxl')
                except Exception: # openpyxl ì‹¤íŒ¨ ì‹œ xlrd ì‹œë„
                    uploaded_file.seek(0); df = pd.read_excel(uploaded_file, engine='xlrd')
                
                df.columns = [str(col).strip() for col in df.columns] # ì»¬ëŸ¼ëª… ê³µë°± ì œê±°
                items_to_process = [row for _, row in df.iterrows() if not row.isnull().all()] # ë¹ˆ í–‰ ì œì™¸
                total_items = len(items_to_process)
            except Exception as e:
                st.error(f"Excel íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); items_to_process = []
    
    if not items_to_process:
        if text_input.strip() or uploaded_file: # ì…ë ¥ ì‹œë„ëŠ” ìˆì—ˆìœ¼ë‚˜ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
            st.info("ë³€í™˜í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        st.subheader("âœ¨ ì²˜ë¦¬ ê²°ê³¼")
        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, item_data_row_or_line in enumerate(items_to_process):
            processed_items += 1
            status_obj, filename, error_msg = (None, None, "ì•Œ ìˆ˜ ì—†ëŠ” ì…ë ¥ í˜•ì‹ ë˜ëŠ” ì²˜ë¦¬ ì˜¤ë¥˜") # ê¸°ë³¸ ì˜¤ë¥˜ ë©”ì‹œì§€
            
            # ê° ì¤„/í–‰ ë²ˆí˜¸ í‘œì‹œìš© ì ‘ë‘ì‚¬
            row_display_prefix = f"ì—‘ì…€ {i+2}í–‰" if is_excel_input else f"í…ìŠ¤íŠ¸ {i+1}ì¤„"

            if is_excel_input:
                status_obj, filename, error_msg = parse_excel_row_to_json(item_data_row_or_line, current_year_for_parsing, row_display_prefix + ": ")
            else: # í…ìŠ¤íŠ¸ ì…ë ¥
                status_obj, filename, error_msg = parse_line_to_json_flexible(item_data_row_or_line, current_year_for_parsing, row_display_prefix + ": ")

            status_text.text(f"ì²˜ë¦¬ ì¤‘... {processed_items}/{total_items} ({filename if filename else 'ë°ì´í„° ë¶„ì„ ì¤‘'})")
            progress_bar.progress(processed_items / total_items if total_items > 0 else 0)

            # ë¡œê·¸ìš© ì‹ë³„ì ìƒì„±
            log_identifier_parts = []
            if status_obj and status_obj.get('customer_phone'): log_identifier_parts.append(status_obj['customer_phone'])
            if status_obj and status_obj.get('customer_name') != DEFAULT_CUSTOMER_NAME : log_identifier_parts.append(status_obj['customer_name'])
            log_identifier = f"({', '.join(log_identifier_parts)})" if log_identifier_parts else ""

            if status_obj and filename: # ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±ëœ ê²½ìš°
                final_state_to_save = get_default_state() # í•­ìƒ ê¸°ë³¸ ìƒíƒœë¡œ ì‹œì‘
                final_state_to_save.update(status_obj)    # íŒŒì‹±ëœ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
                
                # STATE_KEYS_TO_SAVE í•„í„°ë§ ë¡œì§ì€ í˜„ì¬ ì‚¬ìš© ì•ˆ í•¨ (ëª¨ë“  íŒŒì‹±ëœ í‚¤ ì €ì¥)
                # í•„ìš”ì‹œ state_manager.pyì—ì„œ STATE_KEYS_TO_SAVEë¥¼ ê°€ì ¸ì™€ í•„í„°ë§ ê°€ëŠ¥
                
                try:
                    gdrive_folder_id_secret = st.secrets.get("gcp_service_account", {}).get("drive_folder_id")
                    # gdrive.save_json_file í•¨ìˆ˜ëŠ” google_drive_helper.pyì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨
                    save_result = gdrive.save_json_file(filename, final_state_to_save, folder_id=gdrive_folder_id_secret)
                    if save_result and save_result.get('id'):
                        log_message = f"âœ… <span style='color:green;'>ì €ì¥ ì„±ê³µ</span>: {filename} {log_identifier} (ID: {save_result.get('id')})"
                        all_log_messages.append(log_message); success_count += 1
                    else:
                        log_message = f"âŒ <span style='color:red;'>ì €ì¥ ì‹¤íŒ¨</span>: {filename} {log_identifier} (ì‘ë‹µ: {save_result})"
                        all_log_messages.append(log_message); error_count += 1
                except AttributeError as ae: # gdrive ëª¨ë“ˆì— save_json_file í•¨ìˆ˜ê°€ ì—†ì„ ê²½ìš° ë“±
                     log_message = f"âŒ <span style='color:red;'>ì €ì¥ í•¨ìˆ˜ ì˜¤ë¥˜</span>: {filename} {log_identifier} (ì˜¤ë¥˜: {ae})"
                     all_log_messages.append(log_message); error_count += 1
                except Exception as e_save:
                    log_message = f"âŒ <span style='color:red;'>ì €ì¥ ì¤‘ ì˜ˆì™¸</span>: {filename if filename else 'ë°ì´í„°'} {log_identifier} ({str(e_save)})"
                    all_log_messages.append(log_message); error_count += 1
            else: # íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” í•„ìˆ˜ ì •ë³´ ëˆ„ë½
                log_message = f"âš ï¸ <span style='color:orange;'>ê±´ë„ˆëœ€/ì˜¤ë¥˜</span>: {error_msg if error_msg else 'ì‚¬ìœ  ë¶ˆëª…'} {log_identifier}"
                all_log_messages.append(log_message); error_count +=1
        
        status_text.empty(); progress_bar.empty() # ì§„í–‰ ìƒíƒœ ì´ˆê¸°í™”
        st.info(f"ì´ ë¶„ì„ ëŒ€ìƒ: {total_items} ê±´ (ì‹¤ì œ ì²˜ë¦¬ ì‹œë„: {processed_items} ê±´)")
        st.success(f"Google Drive ì €ì¥ ì„±ê³µ: {success_count} ê±´")
        if error_count > 0: st.error(f"ì‹¤íŒ¨ ë˜ëŠ” ê±´ë„ˆëœ€: {error_count} ê±´")
        else: st.info(f"ì‹¤íŒ¨ ë˜ëŠ” ê±´ë„ˆëœ€: {error_count} ê±´") # ì˜¤ë¥˜ê°€ ì—†ì–´ë„ ê±´ë„ˆë›´ í•­ëª©ì´ ìˆì„ ìˆ˜ ìˆìŒ

        if all_log_messages:
            # ì˜¤ë¥˜ê°€ ìˆê±°ë‚˜, ì„±ê³µ ê±´ìˆ˜ê°€ ì „ì²´ ê±´ìˆ˜ë³´ë‹¤ ì ì„ ë•Œë§Œ ê¸°ë³¸ìœ¼ë¡œ í¼ì³ì„œ ë³´ì—¬ì¤Œ
            expanded_log = (error_count > 0 or success_count < total_items)
            with st.expander("â–¼ ìƒì„¸ ì²˜ë¦¬ ë¡œê·¸ ë³´ê¸° (í´ë¦­)", expanded=expanded_log):
                # ë¡œê·¸ ë©”ì‹œì§€ HTML ìƒì„± (ë” ì•ˆì „í•œ ë°©ì‹ ê³ ë ¤ ê°€ëŠ¥, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ replace ì‚¬ìš©)
                log_html = "".join([f"<div style='font-size:small; margin-bottom:3px;'>{log.replace('âœ…','âœ”ï¸')}</div>" for log in all_log_messages])
                st.markdown(log_html, unsafe_allow_html=True)
